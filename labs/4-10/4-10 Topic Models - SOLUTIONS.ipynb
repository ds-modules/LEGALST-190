{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [LEGALST-190] Lab 4/10: Topic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab will cover latent dirichlet allocation and topic models using `gensim` and `scikit-learn`.\n",
    "\n",
    "*Estimated Time: 35 Minutes *\n",
    "\n",
    "### Table of Contents\n",
    "[The Data](#section data)<br>\n",
    "1 - [Using Gensim to Implement a LDA Model](#section 1)<br>\n",
    "2 - [Using scikit-learn](#section 2)<br>\n",
    "3 - [Finding topics from UN Debates](#section 3)<br>\n",
    "\n",
    "**Dependencies:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-3.4.0-cp36-cp36m-win_amd64.whl (22.5MB)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\gibson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from gensim)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\gibson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from gensim)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\gibson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from gensim)\n",
      "Collecting smart-open>=1.2.1 (from gensim)\n",
      "  Downloading smart_open-1.5.7.tar.gz\n",
      "Collecting boto>=2.32 (from smart-open>=1.2.1->gensim)\n",
      "  Downloading boto-2.48.0-py2.py3-none-any.whl (1.4MB)\n",
      "Collecting bz2file (from smart-open>=1.2.1->gensim)\n",
      "  Downloading bz2file-0.98.tar.gz\n",
      "Requirement already satisfied: requests in c:\\users\\gibson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from smart-open>=1.2.1->gensim)\n",
      "Collecting boto3 (from smart-open>=1.2.1->gensim)\n",
      "  Downloading boto3-1.7.4-py2.py3-none-any.whl (128kB)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\gibson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\gibson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\gibson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gibson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests->smart-open>=1.2.1->gensim)\n",
      "Collecting botocore<1.11.0,>=1.10.4 (from boto3->smart-open>=1.2.1->gensim)\n",
      "  Downloading botocore-1.10.4-py2.py3-none-any.whl (4.2MB)\n",
      "Collecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.2.1->gensim)\n",
      "  Downloading jmespath-0.9.3-py2.py3-none-any.whl\n",
      "Collecting s3transfer<0.2.0,>=0.1.10 (from boto3->smart-open>=1.2.1->gensim)\n",
      "  Downloading s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n",
      "Requirement already satisfied: docutils>=0.10 in c:\\users\\gibson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from botocore<1.11.0,>=1.10.4->boto3->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: python-dateutil<2.7.0,>=2.1 in c:\\users\\gibson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from botocore<1.11.0,>=1.10.4->boto3->smart-open>=1.2.1->gensim)\n",
      "Building wheels for collected packages: smart-open, bz2file\n",
      "  Running setup.py bdist_wheel for smart-open: started\n",
      "  Running setup.py bdist_wheel for smart-open: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\Gibson\\AppData\\Local\\pip\\Cache\\wheels\\cf\\54\\36\\b003d8c2d26aadffc21f0677009ed53cf9575a97fc71fbba76\n",
      "  Running setup.py bdist_wheel for bz2file: started\n",
      "  Running setup.py bdist_wheel for bz2file: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\Gibson\\AppData\\Local\\pip\\Cache\\wheels\\31\\9c\\20\\996d65ca104cbca940b1b053299b68459391c01c774d073126\n",
      "Successfully built smart-open bz2file\n",
      "Installing collected packages: boto, bz2file, jmespath, botocore, s3transfer, boto3, smart-open, gensim\n",
      "Successfully installed boto-2.48.0 boto3-1.7.4 botocore-1.10.4 bz2file-0.98 gensim-3.4.0 jmespath-0.9.3 s3transfer-0.1.13 smart-open-1.5.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gibson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#!pip install gensim\n",
    "from gensim import corpora, models\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## The Data<a id='section data'></a>\n",
    "\n",
    "For this lab, we'll use sci-kit learn's `20 newsgroups` dataset, which is a list of approximately 18,000 newsgroup posts. Because of its size, we'll only be working with about 750 posts. At the end of this lab, we'll also work with a selected portion of the UN Data. \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Using Gensim to Implement a LDA Model<a id='section 1'></a>\n",
    "\n",
    "### What Is Latent Dirichlet Allocation?\n",
    "Latent dirichlet allocation is a way of discovering topics in a set of documents, generating topics based on word frequency. LDA is a probabilistic bag-of-words model that makes an assumption that documents are produced from a variety of topics that produce words with certain probilities. Then it backtracks, finding a set of certain topics that would have created the documents.\n",
    "\n",
    "----\n",
    "\n",
    "### Using `gensim`\n",
    "\n",
    "We'll use the LDA algorithm from `gensim`, a python library for topic modelling.\n",
    "\n",
    "Let's get working with the data. The `20 newsgroups` data is under the name `20newgroups_data.csv` in the data folder. \n",
    "\n",
    "**Question 1.1:** Retrieve the posts from the DataFrame and assign the list to a variable named `documents`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/20newsgroups_data.csv')\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\n \\nI read somewhere, I think in Morton Smith's _Jesus the Magician_, that\\nold Lazarus wasn't dead, but going in the tomb was part of an initiation\\nrite for a magi-cult, of which Jesus was also a part.   It appears that\\na 3-day stay was normal.   I wonder .... ?\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SOLUTION\n",
    "data = pd.read_csv('data/20newsgroups_data.csv')\n",
    "documents = data['posts'].values\n",
    "documents[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! We now have data we can work with. Before we start anything, we must clean the text!\n",
    "\n",
    "Just to review, we want to process our text by:<br>\n",
    "1) Tokenizing our document<br>\n",
    "2) Removing stop words (remove meaningless words)<br>\n",
    "3) Stemming or merging words that have equivalent meanings<br>\n",
    "\n",
    "<a id='gensim'></a>**Question 1.2:** Tokenize and stem the text in `documents` and filter your tokens by using both `stop` and `more_stops` and punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "punctuation = string.punctuation\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "more_stops = ['--', '``', \"''\", \"s'\", \"\\'s\", \"n\\'t\", \"...\", \"\\'m\", \"-*-\", \"-|\"]\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Potential Solution\n",
    "stop = stopwords.words('english')\n",
    "punctuation = string.punctuation\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "more_stops = ['--', '``', \"''\", \"s'\", \"\\'s\", \"n\\'t\", \"...\", \"\\'m\", \"-*-\", \"-|\"] \n",
    "tokenized = []\n",
    "for i in documents:\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(i) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = [x for x in tokens if x not in punctuation and x not in more_stops]\n",
    "    stopped_tokens = [x for x in filtered_tokens if not x in stop]\n",
    "    stemmed_tokens = [stemmer.stem(i) for i in stopped_tokens]\n",
    "    tokenized.append(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our tokenized documents, we have to convert it to a *document-term matrix* which can be done by instantiating a `gensim` dictionary object. Our first step is to turn our tokenized documents into a \"dictionary\" that maps a word to its integer ID, like a bag-of-words model. <a id='Q1.3'></a>\n",
    "\n",
    "**Question 1.3:** Implement a gensim dictionary from the `corpora` package and assign it to a variable named `dictionary`. You can look [at the documentation](https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary) for the corpora package if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOLUTION\n",
    "dictionary = corpora.Dictionary(tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the last step before we implement the model! We must convert our documents to bag-of-words format using our dictionary. Every document is represented as a list of tuples of the word's integer ID and its frequency. This list of 400 documents represents our document-term matrix.\n",
    "\n",
    "**Question 1.4:** Using `dictionary` from the previous question, convert to your tokenzied documents into a bag-of-words format and store it to a variable named `corpus`. We want to use `doc2bow()` method ***for every document*** in our tokenized text. The documentation is linked [here](https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary.doc2bow).\n",
    "\n",
    "You should end up with a list of tuples for each document and make sure that `len(corpus)` is 738. Calling `corpus[i]` for some integer i should return something of the form `[(16, 2), (58, 1), (59, 1),...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOLUTION\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a document-term matrix, weâ€™re ready to generate an LDA model!\n",
    "\n",
    "The cell below is an example of an implementation of a `gensim` LDA model. Run the cell and take a look at what it displays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0\n",
      "0.007*\"would\" + 0.004*\"use\" + 0.004*\"one\" + 0.004*\"peopl\" + 0.003*\"get\" + 0.003*\"think\" + 0.003*\"like\" + 0.003*\"even\" + 0.002*\"could\" + 0.002*\"say\"\n",
      "\n",
      "Topic 1\n",
      "0.006*\"one\" + 0.005*\"peopl\" + 0.005*\"think\" + 0.005*\"use\" + 0.004*\"like\" + 0.004*\"would\" + 0.004*\"go\" + 0.004*\"get\" + 0.004*\"know\" + 0.004*\"time\"\n",
      "\n",
      "Topic 2\n",
      "0.006*\"use\" + 0.004*\"one\" + 0.003*\"system\" + 0.003*\"would\" + 0.003*\"like\" + 0.003*\"make\" + 0.003*\"govern\" + 0.003*\"new\" + 0.003*\"get\" + 0.003*\"also\"\n",
      "\n",
      "Topic 3\n",
      "0.009*\"would\" + 0.005*\"one\" + 0.005*\"like\" + 0.005*\"peopl\" + 0.004*\"use\" + 0.004*\"god\" + 0.004*\"know\" + 0.003*\"get\" + 0.003*\"good\" + 0.003*\"hiv\"\n",
      "\n",
      "Topic 4\n",
      "0.015*\"1\" + 0.013*\"2\" + 0.006*\"3\" + 0.004*\"get\" + 0.003*\"4\" + 0.003*\"know\" + 0.003*\"copi\" + 0.003*\"one\" + 0.003*\"6\" + 0.003*\"make\"\n",
      "\n",
      "Topic 5\n",
      "0.007*\"use\" + 0.005*\"one\" + 0.005*\"would\" + 0.004*\"send\" + 0.003*\"file\" + 0.003*\"get\" + 0.003*\"know\" + 0.003*\"like\" + 0.003*\"also\" + 0.003*\"imag\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ldamodel = models.LdaModel(corpus, \n",
    "                           id2word=dictionary,\n",
    "                           num_topics=6,\n",
    "                           chunksize=270, \n",
    "                           update_every=20,\n",
    "                           passes=3)\n",
    "#We have defined a helper function show_topics that takes in the model as an argument.\n",
    "show_topics(ldamodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Our model returned some topics! We have a jumble of words and numbers, but remember that LDA is a probabilistic model. For clarity, the `show_topics` function utilizes the `LdaModel` method `.show_topics()` which gives us the words that contribute the most to `num_topics` random topics (random because we aren't defining the topics). The numbers in front the words represent the probability of that word appearing in the topic. If we look at **topic 2**, we can infer from the proportions in front of the word that the topic is more about 1 and 2 rather than \"people\", which has a lower value than the first two. \n",
    "\n",
    "Although we aren't explicitly defining the topics, we are telling the computer how many topics to look for. LDA treats each document as a mix of words and a mix of topics. It chooses words that contribute to a topic and finds certain topics that describe a document.\n",
    "\n",
    "Unfortunately, we are working with a pretty small set of ducments and our topics would be more defined with a larger corpus, but we can still work with our data to get defined topics. Let's start defining more optimal parameters for our model!\n",
    "\n",
    "----\n",
    "\n",
    "There are quite a few parameters for generating the `LdaModel` that affect the quality of the topics returned. We'll go over some of the helpful and important parameters to use when implementing a LDA model in `gensim`.\n",
    "\n",
    "| Required Parameters        |Value                          | Default | What it does  |\n",
    "| :-------------------------:|:-----------------------------:| --|:-------------:|\n",
    "|                corpus      | corpus (doc-term matrix) | None | This specifies your LDA model parameters. |\n",
    "| id2word     | `gensim` dictionary | None | The doc-term matrix to word <br>integer ID mapping. |\n",
    "| num_topics<br> | integer | 100 |Specifies the number of underlying topics <br> in your documents. Usually, the fewer <br> documents you have, the smaller number <br> you assign [(this is a hot topic!)](https://www.quora.com/Latent-Dirichlet-Allocation-LDA-What-is-the-best-way-to-determine-k-number-of-topics-in-topic-modeling).<br>|\n",
    "\n",
    "\n",
    "| Optional (but helpful) Parameters   |Default | What it does  |\n",
    "|:------------------------------------|------- |:-------------------------------:|\n",
    "| passes | 1 | How many times you want to iterate through the corpus.<br> The more passes, the more accurate your model will be, <br> although  it can take longer time if you have a large dataset. |\n",
    "|chunksize | 2000 | The size of the batch documents you want to run through.<br> e.g. chunksize = 10, we run 10 documents at a time.| \n",
    "|update_every |1 | Update the model after every `n` number of chunks. |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.5:** After reviewing the parameters, go back to the previous model. What is problematic about it and its results? Which parameters do you think you should change first to get more explicit results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Q1.6a'></a> **Question 1.6a:** Improve the previous LDA model by adjusting the parameters  [(documentation)](https://radimrehurek.com/gensim/models/ldamodel.html#gensim.models.ldamodel.LdaModel). Try to get as clear topics as possible! Remember to call `show_topics` on your model to print out the words for your topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0\n",
      "0.012*\"blue\" + 0.007*\"second\" + 0.005*\"orbit\" + 0.005*\"period\" + 0.005*\"bassen\" + 0.004*\"proton\" + 0.004*\"end\" + 0.004*\"launch\" + 0.004*\"play\" + 0.004*\"greek\"\n",
      "\n",
      "Topic 1\n",
      "0.008*\"would\" + 0.008*\"one\" + 0.008*\"peopl\" + 0.006*\"think\" + 0.006*\"like\" + 0.006*\"god\" + 0.006*\"time\" + 0.005*\"know\" + 0.005*\"make\" + 0.004*\"say\"\n",
      "\n",
      "Topic 2\n",
      "0.008*\"list\" + 0.007*\"send\" + 0.007*\"file\" + 0.006*\"x\" + 0.005*\"use\" + 0.005*\"comput\" + 0.005*\"mail\" + 0.005*\"request\" + 0.005*\"graphic\" + 0.004*\"score\"\n",
      "\n",
      "Topic 3\n",
      "0.024*\"1\" + 0.022*\"2\" + 0.011*\"3\" + 0.008*\"0\" + 0.008*\"4\" + 0.007*\"p\" + 0.005*\"copi\" + 0.005*\"n\" + 0.005*\"p-\" + 0.005*\"6\"\n",
      "\n",
      "Topic 4\n",
      "0.006*\"hiv\" + 0.005*\"april\" + 0.004*\"aid\" + 0.004*\"diseas\" + 0.004*\"health\" + 0.003*\"inform\" + 0.003*\"jewish\" + 0.003*\"6\" + 0.003*\"find\" + 0.003*\"new\"\n",
      "\n",
      "Topic 5\n",
      "0.008*\"would\" + 0.008*\"get\" + 0.007*\"use\" + 0.007*\"one\" + 0.007*\"like\" + 0.005*\"know\" + 0.005*\"go\" + 0.005*\"car\" + 0.005*\"could\" + 0.005*\"problem\"\n",
      "\n",
      "Topic 6\n",
      "0.013*\"pleas\" + 0.007*\"use\" + 0.006*\"interest\" + 0.006*\"packag\" + 0.006*\"space\" + 0.005*\"softwar\" + 0.004*\"pictur\" + 0.004*\"post\" + 0.004*\"contact\" + 0.004*\"e-mail\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Possible Solution\n",
    "possible_model = models.LdaModel(corpus, \n",
    "                                 id2word=dictionary,\n",
    "                                 num_topics=7,\n",
    "                                 chunksize=75, \n",
    "                                 update_every=3,\n",
    "                                 passes=15)\n",
    "show_topics(possible_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.6b:** What are some topics that you can infer from your optimized model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.6c:** Did you notice any patterns while changing values of certain parameters (how did num_topics change the quality of results)? What worked in giving you reasonable, clear topics and what didn't? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Section 2: Using `scikit-learn`<a id='section 2'></a>\n",
    "\n",
    "Along with `gensim`,  we can also use `scikit-learn` to implement a LDA model. Using the `scikit-learn` algorithm is less clear, since a lot of the work is done by the computer. But, by going through the `gensim` algorithm, we now have an idea how LDA works, and using the `scikit-learn` algorithm will be a little more clear. \n",
    "\n",
    "You may be wondering, *why did we do all of that work in the first section when we can just use `scikit-learn` to implement a LDA model?* \n",
    "\n",
    "The motivation to use `gensim` is that you have much more control over how you can implement your model. This is a really big benefit if you want to find topics without having too much overlap, repetition, or inconsistency. For example, with `gensim`, you can tokenize and stem your documents in any way you want. But with `scikit-learn`, you don't have as much control over how you manipulate your data. Another example is the ability to filter your `gensim` dictionary instance, which you will explore later in the last section. If you prefer a more explicit method of implementing a topic model and want command over your data, then `gensim` is a great option.\n",
    "\n",
    "Anyway, let's get started with using `scikit-learn`!\n",
    "\n",
    "----\n",
    "\n",
    "**Question 2.1:** In order to implement a LDA model using `scikit-learn`, we must extract features to a matrix using either the count vectorizer or the tf-idf vectorizer. Which one do we use and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here*"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#SOLUTION\n",
    "Because LDA is a probabilistic model, we use the CountVectorizer because we need raw counts of numbers, not weighted values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "If you answered a count vectorizer to the previous question, you're right! Since LDA is a probabilistic model, we only need the raw term counts.\n",
    "\n",
    "<a id='sklearn'></a>\n",
    "\n",
    "**Question 2.2:** Instantiate a count vectorizer with the parameters `max_df=.95`, `min_df=2`, and `stop_words='english'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOLUTION\n",
    "countvec = CountVectorizer(max_df=.95, \n",
    "                           min_df=2, \n",
    "                           stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the vectorizer, we can transform our data into a document-term matrix, as well as use `.get_feature_names()` to get the word to integer ID mapping like we did in [question 1.3](#Q1.3).\n",
    "\n",
    "**Question 2.3:** Use your vectorizer to transform the same dataset from the first section of this lab to a document-term matrix (concept is similar to Q1.4) and get the feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOLUTION\n",
    "cv = countvec.fit_transform(documents)\n",
    "cv_feature_names = countvec.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're almost done! The last step is to implement the model, so we can get our topics. Similar to `gensim`, there are parameters that should be adjusted to fit your documents.\n",
    "\n",
    "| Parameters <br> [(documentation)](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html)|Default | What it does  |\n",
    "| :-------------------------:|:-----------------------------:|:-------------:|\n",
    "|          n_components      | 10 | Equivalent to `num_topics` in the `gensim` model. This <br> specifies the number of latent topics in your documents. |\n",
    "| max_iter | 10 | Equivalent to `passes` in the `gensim` model. |\n",
    "| batch_size | 128 | Equivalent to `chunksize` |\n",
    "\n",
    "**Question 2.4:** Implement the LDA model using `LatentDirichletAllocation`. Don't forget to fit your document-term matrix from the previous question!\n",
    "\n",
    "**Note:** Set the `learning_method` parameter to `'online'`, which is its default (for the latest version of scikit-learn) but will throw a deprecation warning if not specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOLUTION\n",
    "lda = LatentDirichletAllocation(n_components=5, \n",
    "                                max_iter=25, \n",
    "                                batch_size = 99,\n",
    "                                learning_method='online').fit(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function `topic_words` is defined for you (from `helper.py`) and it takes in three arguments:\n",
    "\n",
    "     1) model: your LDA model\n",
    "     2) feature_names: the feature names from the vectorizer\n",
    "     3) num_top_words: number of words you want displayed\n",
    "\n",
    "It prints out the topic number and the words that fall under that topic, although it does not display weight of words like `gensim`.\n",
    "\n",
    "**Question 2.5:** Specify the number of words you want displayed and call `topic_and_words` on the LDA model from the previous question. \n",
    "\n",
    "<sub>**Note:** If your topics are repetitive or aren't very coherent, try tweaking the parameters in the previous question.</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "god gm magi church jesus christ belief bible believe mary satan heaven greek christian did\n",
      "Topic 1:\n",
      "car blues game 10 said year just government encryption didn period season record going play\n",
      "Topic 2:\n",
      "win titan int mission launch probe jupiter vram centaur earth cb orbiter memory orbit space\n",
      "Topic 3:\n",
      "edu graphics mail use send data software pub using com windows computer space thanks file\n",
      "Topic 4:\n",
      "people like just don know think time good new say way ve said want years\n"
     ]
    }
   ],
   "source": [
    "#Possible solution\n",
    "num_top_words = 15\n",
    "topic_words(lda, cv_feature_names, num_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "**Question 2.6:** Did your model yield clear, interpretable results? How does it compare to the LDA model you created in [section one](#Q1.6a)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Section 3: Finding topics from UN General Debates<a id='section 3'></a>\n",
    "\n",
    "We have two ways of implementing a LDA model, let's try both on the UN General Debates dataset. We can now get an idea of what was discussed at a specific session through topic modelling!\n",
    "\n",
    "**Question 3.1**: Load `un-general-debates-2015` from the data folder and extract the data from the 'text' column. This file contains the data from the 70th session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "un = pd.read_csv('data/un-general-debates-2015.csv')\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOLUTION\n",
    "un = pd.read_csv('data/un-general-debates-2015.csv')\n",
    "un_text = un['text'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2:** First implement a LDA model using `gensim`. Follow similar steps from the [first section](#gensim), and adjust your parameters accordingly! Use the `show_topics` function to display your topics.\n",
    "\n",
    "**Tip:** Use the `filter_extremes(no_below=<int>)` method [(documentation)](https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary.filter_extremes) on your `gensim` dictionary, which helps filter through tokens based on frequency (in this case it'll keep any tokens contained in at least the specified integer number of documents). Feel free to use other parameters in `filter_extremes` to optimize your topics! \n",
    "\n",
    "As mentioned at the beginning of [section 2](#section 2), you really do have a lot of control over your model and I encourage you to utilize these tools to refine your topic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0\n",
      "0.022*\"african\" + 0.008*\"sign\" + 0.007*\"congo\" + 0.006*\"appeal\" + 0.006*\"despit\" + 0.006*\"contin\" + 0.006*\"kingdom\" + 0.005*\"west\" + 0.005*\"central\" + 0.005*\"mali\"\n",
      "\n",
      "Topic 1\n",
      "0.036*\"palestinian\" + 0.032*\"israel\" + 0.026*\"palestin\" + 0.022*\"isra\" + 0.021*\"islam\" + 0.018*\"yemen\" + 0.015*\"syrian\" + 0.013*\"muslim\" + 0.013*\"iran\" + 0.012*\"settlement\"\n",
      "\n",
      "Topic 2\n",
      "0.004*\"trade\" + 0.003*\"invest\" + 0.003*\"reduc\" + 0.003*\"weapon\" + 0.003*\"energi\" + 0.003*\"target\" + 0.003*\"benefit\" + 0.003*\"forum\" + 0.003*\"risk\" + 0.003*\"enhanc\"\n",
      "\n",
      "Topic 3\n",
      "0.006*\"european\" + 0.005*\"say\" + 0.004*\"iraq\" + 0.004*\"never\" + 0.004*\"home\" + 0.004*\"islam\" + 0.004*\"militari\" + 0.004*\"ask\" + 0.004*\"know\" + 0.003*\"think\"\n",
      "\n",
      "Topic 4\n",
      "0.037*\"island\" + 0.023*\"ocean\" + 0.017*\"caribbean\" + 0.014*\"pacif\" + 0.013*\"fiji\" + 0.011*\"sid\" + 0.011*\"sea\" + 0.010*\"saint\" + 0.010*\"cuba\" + 0.010*\"venezuela\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Possible solution using gensim\n",
    "more_stops = ['--', '``', \"''\", \"s'\", \"\\'s\", \"n\\'t\", \"...\"]\n",
    "un_corp = []\n",
    "for i in un_text:\n",
    "    un_tokens = [word.lower() for sent in nltk.sent_tokenize(i) for word in nltk.word_tokenize(sent)]\n",
    "    un_filtered_tokens = [x for x in un_tokens if x not in punctuation and x not in more_stops]\n",
    "    un_stopped_tokens = [x for x in un_filtered_tokens if not x in stop]\n",
    "    un_stemmed_tokens = [stemmer.stem(i) for i in un_stopped_tokens]\n",
    "    un_corp.append(un_stemmed_tokens)\n",
    "\n",
    "un_dictionary = corpora.Dictionary(un_corp)\n",
    "\n",
    "un_dictionary.filter_extremes(no_below=5, no_above=.4)\n",
    "\n",
    "un_d_t = [un_dictionary.doc2bow(i) for i in un_corp]\n",
    "\n",
    "un_lda = models.LdaModel(un_d_t, num_topics=5,\n",
    "                            id2word=un_dictionary, \n",
    "                            chunksize=20, \n",
    "                            update_every=1,\n",
    "                            passes=17)\n",
    "\n",
    "show_topics(un_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3:** Now, implement a model using `scikit-learn`. Again, follow similar steps from the [second section](#sklearn) and adjust parameters accordingly. You can display your topics using `topic_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "islands solomon papua guinea pacific melanesian indonesia caledonia taiwan shelf\n",
      "Topic 1:\n",
      "belize grenadines vincent redress dominican passengers defer awesome chain fauna\n",
      "Topic 2:\n",
      "venezuela latin argentina guyana trinidad tobago american bolivia uruguay creditors\n",
      "Topic 3:\n",
      "madagascar rights global community climate terrorism council republic agenda challenges\n",
      "Topic 4:\n",
      "global rights sustainable climate change support agenda state council efforts\n"
     ]
    }
   ],
   "source": [
    "#Possible solution using sklearn\n",
    "countvec = CountVectorizer(max_df=.90, \n",
    "                           min_df=2, \n",
    "                           stop_words='english')\n",
    "\n",
    "un_cv = countvec.fit_transform(un_text)\n",
    "un_cv_feature_names = countvec.get_feature_names()\n",
    "\n",
    "un_lda = LatentDirichletAllocation(n_components=5, \n",
    "                                   max_iter=30,\n",
    "                                   learning_decay=0.7,\n",
    "                                   batch_size=30,\n",
    "                                   learning_method='online').fit(un_cv)\n",
    "\n",
    "topic_words(un_lda, un_cv_feature_names, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "**Question 3.4:** Which algorithm yielded more well-defined topics? You can also skim the resolutions passed [here](http://research.un.org/en/docs/ga/quick/regular/70) for reference. What do you think are some factors that need to be considered about the data when choosing an algorithm and adjusting its parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.5:** What are some differences that you noticed between the `gensim` and `scikit-learn` algorithms? What are some of their drawbacks? Do you prefer one over the other and if so, why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Awesome! Now you know how to implement a topic model two ways using `gensim` and `scikit-learn`. Even though `scikit-learn` is more straightforward and requires less work to implement, the control you have over `gensim` is very valuable and can result in more distinct topics.\n",
    "\n",
    "Ultimately, the choice is yours and I hope having both options helps you generate great topic models!\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography\n",
    "\n",
    " - Chen, Edwin, Introduction to latent dirichlet allocation. http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/\n",
    " - Use of `20newsgroups` data set adapted from Topic Modelling tutorial by Aneesha Bakharia\n",
    " https://medium.com/mlreview/topic-modeling-with-scikit-learn-e80d33668730\n",
    " - Resolutions from UN 70th session: http://research.un.org/en/docs/ga/quick/regular/70\n",
    " - Text cleaning code adapted from notebook by Alex Estes https://github.com/dlab-berkeley/python-text-analysis/blob/master/Intro_to_TextAnalysis/Intro_to_TextAnalysis.ipynb\n",
    "\n",
    "----\n",
    "Notebook developed by: Jason Jiang\n",
    "\n",
    "Data Science Modules: http://data.berkeley.edu/education/modules"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
