{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [LEGALST-190] Lab 4/17: Feature Selection\n",
    "\n",
    "This lab will cover feature selection in order to train a machine learning model using `scikit-learn`. With complex datasets with 50+ features, we would run into the problem of overfitting your model and a long run time if all features were to be used. Feature selection is used in machine learning to avoid those type of issues. \n",
    "\n",
    "Estimated time: 35 minutes\n",
    "\n",
    "### Table of Contents\n",
    "[The Data](#section data)<br>\n",
    "1 - [Second Model](# section 1)<br>\n",
    "2 - [Intro to Feature Removal Intuition](#section 2)<br>\n",
    "3 - [Checking Results](#section 3)<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all libraries \n",
    "\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "#matplotlin\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#scikit-learn\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data: Bike Sharing<a id='section data'></a>\n",
    "\n",
    "By now, I'm sure you have been exposed to bike sharing dataset several times in this lab. This lab's data describes one such bike sharing system in Washington D.C., from UC Irvine's Machine Learning Repository.\n",
    "\n",
    "Information about the dataset: http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike = pd.read_csv('data/day.csv', index_col=0)\n",
    "# reformat the date column to integers that represent the day of the year, 001-366\n",
    "bike['dteday'] = pd.to_datetime(bike['dteday'].unique()).strftime('%j')\n",
    "\n",
    "# drop casual and registered riders because we want to predict the number of total riders\n",
    "bike = bike.drop(['casual', 'registered'], axis = 1)\n",
    "\n",
    "bike.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to become familiar with this data set again, feel free to refer back to lab 2-22."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how feature selection can change the accuracy for the better or worse, let's try to make a classifer that uses all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the features used to predict riders\n",
    "X = bike.drop(['cnt'], axis = 1)\n",
    "\n",
    "# the number of riders (target)\n",
    "y = bike['cnt']\n",
    "\n",
    "# set the random seed\n",
    "np.random.seed(10)\n",
    "\n",
    "# split the data with a 0.80 and 0.20 proportion respectively for train size and test size\n",
    "# train_test_split returns 4 values: X_train, X_test, y_train, y_test \n",
    "X_train, X_test, y_train, y_test = ...\n",
    "\n",
    "# create a linear regression model\n",
    "first_model_reg = ...\n",
    "\n",
    "#fit your model\n",
    "first_model = first_model_reg.fit(..., ...)\n",
    "\n",
    "#predict X_train using your model\n",
    "first_pred = first_model.predict(...)\n",
    "\n",
    "#predict X_test using your model\n",
    "test_pred = first_model.predict(...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to check the error between the predicted values and the actual values, I have defined the root mean square error for you. Recall that the equation is the mean squared error of a predicted set of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(pred, actual):\n",
    "    return np.sqrt(np.mean((pred - actual) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the rmse of your models\n",
    "\n",
    "first_train_error = rmse(..., ...)\n",
    "\n",
    "first_test_error = rmse(.., ...)\n",
    "\n",
    "print(\"Training RMSE:\", first_train_error)\n",
    "print(\"Test RMSE:\", first_test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Second Model\n",
    "\n",
    "Our training and test errors seem to be pretty high. Let's see how we can improve our model by using feature selection. This process is often accompanied by lots of Exploratory Data Analysis (EDA). First we will look at which features correlate to our target feature (`cnt`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1:** Plot a few EDA yourself to become familar with the correlation values between certain features with the number of riders.\n",
    "\n",
    "**hint:** I recommend looking into heat maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2:** Looking at your EDA, how will that help you select which features to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:* sample answer\n",
    "- Looking at the correlations between all features and cnt, I would pick the ones with correlation values higher than 0.50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3:** List out features that would be important to select for your model. Make sure to not include registered or casual riders in your features list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ...\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.4:** Now create a `linear regression` model with the features that you have selected to predict the number of riders(`cnt`). \n",
    "\n",
    "First, separate your data into two parts, a dataframe containing the features used to make our prediction (X) and an array of the true values (y). To start, let's predict the total number of riders (y) using every feature that isn't a rider count (X). Then split the train_size and test_size containing 80% and 20% of the data respectively. Scikit-learn's `test_train_split function` will help here.\n",
    "\n",
    "You can refer back to lab 2-22 if needed.\n",
    "\n",
    "*Note that Lasso and Ridge models would use the same steps below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the features used to predict riders\n",
    "X = bike[features]\n",
    "\n",
    "# the number of riders\n",
    "y = bike['cnt']\n",
    "\n",
    "# set the random seed\n",
    "np.random.seed(10)\n",
    "\n",
    "# split the data\n",
    "# train_test_split returns 4 values: X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a linear regression model\n",
    "lin_reg = ...\n",
    "\n",
    "# fit the model\n",
    "lin_model = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the number of riders\n",
    "\n",
    "lin_pred = ...\n",
    "\n",
    "# plot the residuals on a scatter plot\n",
    "plt.scatter(y_train, lin_pred)\n",
    "\n",
    "plt.title('Linear Model (OLS)')\n",
    "plt.xlabel('actual value')\n",
    "plt.ylabel('predicted value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.5:** What is the rmse for both the prediction of X_train and X_test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict your X_test here\n",
    "lin_test_pred = ...\n",
    "\n",
    "second_train_error = ...\n",
    "second_test_error = ...\n",
    "\n",
    "print(\"Training RMSE:\", second_train_error)\n",
    "print(\"Test RMSE:\", second_test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hmm... maybe our selected features did not improve the error as much. Let's see how we can improve our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Introduction to Feature Removal Intuition<a id = 'section 2'></a>\n",
    "\n",
    "As a good rule of thumb, we typically wish to pick features that have roughly more than a 0.50 correlation with the target column. Also, even though not relevant to the bike sharing dataset, it is often best to remove columns that contain a high ratio of null values. However, sometimes null values represent 0 instead of data actually missing! So always be on the look out when you have to clean data.\n",
    "\n",
    "Of course, with any tedious and error prone process there is always a short cut that reduces time and human error. In part 1, you used your own intuition to pick out features that correlate the highest with the target feature. However, we can use `scikit-learn` to help pick the important features for us. \n",
    "\n",
    "Feature selection methods can give you useful information on the relative importance or relevance of features for a given problem. You can use this information to create filtered versions of your dataset and increase the accuracy of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Features with Low Variance\n",
    "\n",
    "In removing features with low variance, all features whose variance does not meet some threshold are removed. In order to remove features that have low variance, you must use normalization on the columns before using VarianceThreshold. This is necessary to bring all the features to same scale. Ensuring standardised feature values implicitly weights all features equally. Otherwise, the variance estimates can be misleading between higher value features and lower value features. By default, normalization is not included in the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we will reload the X and y values for you \n",
    "X = bike.drop(['cnt'], axis = 1)\n",
    "\n",
    "# the number of riders\n",
    "y = bike['cnt']\n",
    "\n",
    "# set the random seed\n",
    "np.random.seed(10)\n",
    "\n",
    "# normalize your data\n",
    "X = preprocessing.normalize(X, norm = 'max', axis = 0)\n",
    "\n",
    "# split the data\n",
    "# train_test_split returns 4 values: X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    train_size=0.80, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1:** What is the current shape of X_train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# code answer here\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `VarianceThreshold` to filter out features that match a 0.1 threshold. If your code produces an error ('No feature in X meets the variance threshold 0.10000') and you believe it is correct, try rerunning the `train_test_split` code block above and rerun the code below.\n",
    "\n",
    "Then you can use `transform` on the X_train. This will select features that match the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use VarianceThreshold \n",
    "sel = ...\n",
    "sel.fit_transform(...)\n",
    "\n",
    "# Subset features with transform\n",
    "X_new = sel.transform(...)\n",
    "\n",
    "#notice how many features are then selected compared to X_train's original features\n",
    "X_new.shape\n",
    "\n",
    "#make sure to also transform X_test so it will match dimensions of X_train\n",
    "X_new_test = sel.transform(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Linear Regression model for your X_new. Recall that X_new is the X_train with selected features.\n",
    "new_lin_reg = LinearRegression()\n",
    "\n",
    "# fit the model\n",
    "new_lin_model = ...\n",
    "\n",
    "#predict X_new\n",
    "new_lin_pred = ...\n",
    "\n",
    "#predict X_new_test\n",
    "new_test_pred = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1:** How does the number of features from X_train compare to X_new?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2:** How does your root mean square error change compared to your model in section 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_train_error = ...\n",
    "third_test_error = ...\n",
    "\n",
    "print(\"Training RMSE:\", third_train_error)\n",
    "print(\"Test RMSE:\", third_test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimiation with scikit-learn\n",
    "\n",
    "According to [Feature Selection in Python with Scikit-Learn](https://machinelearningmastery.com/feature-selection-in-python-with-scikit-learn/), recursive feature elimination works by “recursively removing attributes and building a model on those attributes that remain. It uses the model accuracy to identify which attributes (and combination of attributes) contribute the most to predicting the target attribute.”\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we will reload the X and y values \n",
    "X = bike.drop(['cnt'], axis = 1)\n",
    "\n",
    "# the number of riders\n",
    "y = bike['cnt']\n",
    "\n",
    "# set the random seed\n",
    "np.random.seed(10)\n",
    "\n",
    "# split the data\n",
    "# train_test_split returns 4 values: X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    train_size=0.80, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a base classifier used to evaluate a subset of attributes\n",
    "model = LinearRegression()\n",
    "\n",
    "# create the RFE model and select 10 attributes\n",
    "rfe = RFE(..., ...)\n",
    "rfe.fit(..., ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check which features have been selected, we can use rfe.support_ to show mask of selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rfe.support_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature ranking, such that ranking_[i] corresponds to the ranking position of the i-th feature. Selected (i.e., estimated best) features are assigned rank 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using rfe, predict your training set\n",
    "new_pred = rfe.predict(...)\n",
    "\n",
    "# now predict your test set\n",
    "new_test_pred = rfe.predict(...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time for errors\n",
    "fourth_train_error = ...\n",
    "fourth_test_error = ...\n",
    "\n",
    "print(\"Training RMSE:\", fourth_train_error)\n",
    "print(\"Test RMSE:\", fourth_test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3:** How does recursive feature elimination change your error?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:* Use the rmse equation to explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "\n",
    "Feature importance is selecting features that are most important from a previous classifier. For example, selecting the most important features from a number of randomized decision trees. \"A decision tree can be used to visually and explicitly represent decisions and decision making. As the name goes, it uses a tree-like model of decisions.\" If you would like to read more, feel free to [click here](https://towardsdatascience.com/decision-trees-in-machine-learning-641b9c4e8052). The main idea behind using the randomized trees is to use many of them to perform prediction. This helps the model to be more robust.\n",
    "\n",
    "Methods that use ensembles of decision trees (like `Random Forest` or `Extra Trees`) can also compute the relative importance of each attribute. These importance values can be used to inform a feature selection process. In this lab, we will be using `Extra Trees`, Random forest will be introduced in the next lab.\n",
    "\n",
    "Below shows the construction of an Extra Trees ensemble of the bike share dataset and the display of the relative feature importance.\n",
    "\n",
    "Once you use `ExtraTreesClassifer` to create a new model, fit the model. Afterwards, you can use `SelectFromModel` to select features using the classifier. Make sure to `transform` your X_train to obtain the selected important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fits a number of randomized decision trees. Use 15 estimators (this value was arbitrarily chosen)\n",
    "# this allows us to select features\n",
    "model = ExtraTreesClassifier(...)\n",
    "\n",
    "#fit your model\n",
    "model.fit(..., ...)\n",
    "\n",
    "# Select the important features of previous model\n",
    "sel = SelectFromModel(model, prefit=True)\n",
    "\n",
    "# Subset features\n",
    "select_X_train = sel.transform(...)\n",
    "\n",
    "# We want to create a train model *hint this model is exactly the same as model ^^\n",
    "sel_model = ExtraTreesClassifier(...)\n",
    "\n",
    "#fit your sel_model with the new X_train\n",
    "sel_model.fit(..., ...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict X_train using the new model\n",
    "y_train_pred = ...\n",
    "\n",
    "# we must also select features from X_test to have number of features match up with the model\n",
    "select_X_test = ...\n",
    "\n",
    "#predict y using select_X_test\n",
    "y_pred = ...\n",
    "\n",
    "fifth_train_error = ...\n",
    "fifth_test_error = ...\n",
    "\n",
    "print(\"Training RMSE:\", fifth_train_error)\n",
    "print(\"Test RMSE:\", fifth_test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4:** Which method gives the best results? Check errors rates between all methods mentioned in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:* Depends on the errors students received."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Checking Results<a id = 'section 3'></a>\n",
    "\n",
    "Note that since Linear Regression is not the only model option, you can use the above methods to fit a new model using either `Lasso` or `Ridge`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1:** Within the scope of this class, what are other methods that can be used to improve estimation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:* possible answers\n",
    "- testing multiple models\n",
    "- averging models\n",
    "- stacking models\n",
    "- change number of attributes in Recursive Feature Elimiation method\n",
    "- increase number of estimates in Feature Importance method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1:** Now that we have gone through different methods of feature selection, let's see how the error changes with each method. I have created the dataframe for you, now graph it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['all_features', 'own_selection', 'variance_theshold', 'rfe', 'important']\n",
    "methods = pd.DataFrame(columns = labels)\n",
    "methods['all_features'] = [first_train_error, first_test_error]\n",
    "methods['own_selection'] = [second_train_error, second_test_error]\n",
    "methods['variance_theshold'] = [third_train_error, third_test_error]\n",
    "methods['rfe'] = [fourth_train_error, fourth_test_error]\n",
    "methods['important'] = [fifth_train_error, fifth_test_error]\n",
    "\n",
    "methods = methods.rename(index={0: 'train'})\n",
    "methods = methods.rename(index={1: 'test'})\n",
    "methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography\n",
    "\n",
    " - Brownlee Jason, An Introduction to Feature Selection. https://machinelearningmastery.com/an-introduction-to-feature-selection/\n",
    " - Brownlee Jason, Feature Selection in Python with Scikit-Learn. https://machinelearningmastery.com/feature-selection-in-python-with-scikit-learn/\n",
    " - Asaithambi Sudharsan, Why, How and When to apply Feature Selection. https://towardsdatascience.com/why-how-and-when-to-apply-feature-selection-e9c69adfabf2\n",
    " - Use of `Bike Share` data set adapted from UC Irvine's Machine Learning Repository. http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset\n",
    " - Some code adapted from Celia Siu: https://csiu.github.io/blog/update/2017/03/06/day10.html\n",
    "\n",
    "----\n",
    "Notebook developed by: Tina Nguyen\n",
    "\n",
    "Data Science Modules: http://data.berkeley.edu/education/modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
