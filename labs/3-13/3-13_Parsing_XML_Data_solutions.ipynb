{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [LEGALST-190] Lab 3/13: Parsing XML Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab will cover parsing XML and attribute lookup, XPath, and web scraping.\n",
    "\n",
    "*Estimated Time: 45 Minutes *\n",
    "\n",
    "### Topics Covered:\n",
    "- XML syntax\n",
    "- locating content with XPATH\n",
    "- Web scraping\n",
    "\n",
    "### Table of Contents\n",
    "[The Data](#section data)<br>\n",
    "1 - [XML Syntax](#section 1)<br>\n",
    "2 - [Using XPath and ElementTree to parse XML](#section 2)<br>\n",
    "3 - [Web Scraping](#section 3)<br>\n",
    "4 - [Putting it all in a dataframe](#section 4)<br>\n",
    "\n",
    "**Dependencies:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.cElementTree as ET #XML Parser\n",
    "from lxml import etree #ElementTree and lxml allow us to parse the XML file.\n",
    "import requests #make request to server\n",
    "import time #pause loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## The Data<a id='section data'></a>\n",
    "\n",
    "In this notebook, you'll be working with XML files from the Old Bailey API (https://www.oldbaileyonline.org/obapi/). These files contain the proceedings of all trials from 1674 to 1913. For this lab, we'll go through the trials from 1754-1756 and 1824-1826. XML (eXtensible Markup Language) provides a hierarchical representation of data contained within different tags and nodes. We'll go over XML syntax later. We will learn how to parse through these XML files from Old Bailey and grab information from sections of an XML file.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: XML Syntax<a id='section 1'></a>\n",
    "\n",
    "First, we'll go over the syntax of a XML file. The basic unit of XML code is called an \"element\" or \"node\" and has a start and ending tag. The tags for each element look something like this:\n",
    "\n",
    "<p style=\"text-align: center;\"> `<exampletag>some text</exampletag>`  </p>\n",
    "\n",
    "Run the next cell to look at the XML file of one of the cases from the OldBailey API!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For now, don't worry about the code for now, we'll go through it later.\n",
    "example = requests.get('https://www.oldbaileyonline.org/obapi/text?div=t17031013-13')\n",
    "print(example.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `interp` tags at the beginning of the file are elements that don't have any plain text content. Note that elements may possibly be empty and not contain any text (i.e. `interp` elements mentioned earlier). If the element is empty, the tag may follow a format that looks similar to `<exampletag/>`, which is equivalent to `<exampletag></exampletag>`.\n",
    "\n",
    "Elements may also contain other elements, which we call \"children\". Most children are indented, but the indents aren't necessary in XML and are used for clarity to show nesting. For example, if we go down to `<persName id=\"t17540116-4-defend46\" type=\"defendantName\">` , we see that the `rs` tag is a child of `persName`. We will explore about children in XML more in the next section. \n",
    "\n",
    "Lastly, elements may have attributes, which are in the format `<exampletag name_of_attribute=\"somevalue\">`. Attributes are designed to store data related to a specific elements. Attributes **must** follow the quotes format (`name = \"value\"`). As you can tell, in this XML file, attributes are everywhere!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "**Question 1.1:** What was the verdict of this case? Was there a punsihment and if so, what was it? List both and state whether you found it as plain text content or as an attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your response here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ANSWER\n",
    "Verdict: guilty, plain text content\n",
    "Punsihment: brandingOnCheek, attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Section 2: Using XPath and `ElementTree` to parse XML<a id='section 2'></a>\n",
    "\n",
    "Now that we know what the syntax and structure of an XML file, let's figure out how to parse through one! We are going to load the same file from the first section and use XPath (XML Path Language) to navigate through elements in this file. \n",
    "\n",
    "XPath is designed to locate content in an XML file and uses a [\"tree\" structure](https://www.researchgate.net/profile/Roger_Moussalli/publication/257631377/figure/fig8/AS:297441854279689@1447927072768/Example-XML-Document-and-XML-Path-Queries-a-Example-XML-Document-b-XML-Tree.png) to extract specific chunks. XPath expressions are made up of \"location steps\" which are separated by forward slashes.\n",
    "\n",
    "First, we need to import the file into an ElementTree instance. The ElementTree format will allow us to go through each element, sorting through tags so we can extract the data we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_file = 'data/old-bailey-example.xml'\n",
    "tree = ET.ElementTree(file=xml_file)\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to start working from the root of the tree as XML files have a tree structure. Let's load the root of our tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = tree.getroot()\n",
    "print(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the root, we can now start working down the tree! With the root, we can find each child of the root by printing the tags. This will also help us for future reference, if we every want to go through other children in the XML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get child tags from root\n",
    "for child in root:\n",
    "    print(child.tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a list of children to work with let's select one using `.find`. Using `.find` requires an XPath expression which will navigate through the hierarchical structure of XML and help us keep track of the path we are taking through this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choose_p = root.find('p')\n",
    "for child in choose_p:\n",
    "    print(child.tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't very helpful, since we're still left with a bunch of tags and on top of that, we have a lot of repeating tags and names. Let's choose `placeName` as our next tag and see what happens. Notice that in our XPath expression, we are using foward slashes to navigate to the next child."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "place_name = root.find('p/placeName')\n",
    "for child in place_name:\n",
    "    print(child.tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing was printed, so it looks like we hit the end! Let's use `.text` to examine the data in this element, following the `.find` path we used to get here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(root.find('p/placeName').text)\n",
    "#alternatively, print(place_name.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking back at the file from earlier, we found where defendant was from. Let's see another feature of XPath we can utilize if, for instance, we know all of the possible children in the XML file. \n",
    "\n",
    "With XPath, you can either use a forward slash to move to the next element or child. So in our expression earlier, by following `p/placeName`, we located any `placeName` element that is a child of `p`. Another way to navigate using XPath is using a period and a double forward slash (`.//`), which looks anywhere down the tree from your current element. So, if we start at the root and want to find any element with the tag `placeName`, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(root.find('.//placeName').text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1:** What happens if you don't have the period before the double slash? What happens if you change the starting element or use the whole XML file?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2:** Find the defendant's name by traversing through the correct elements. You can check your answer in the printed XML file from [section 1](#section 1).\n",
    "\n",
    "**Tip:** `print` your final expression so that it looks pretty!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(...) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                  Samuel \n",
      "                  Davis\n",
      "               \n"
     ]
    }
   ],
   "source": [
    "#SOLUTION\n",
    "print(tree.find('p/persName').text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***WARNING*:** If you want to use `//` to find all elements with a specific child, you need to add a period (`.//`), since the node you're currently at most likely not absolute element ( the whole tree). If you want to try it out yourself, using `root.find(//placeName)` should give you an error but `root.find(.//placeName)` should give you what you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Luckily, we can use `.getiterator()`, a really helpful method from ElementTree. It creates an object which will let us iterate through all elements in the file. Using this method is powerful, as we can print each element name utilizing `.tag` or see the data for each element with `.text` and `.attrib`.\n",
    "\n",
    "We can use `.getiterator()` on `tree`, our ElementTree instance. We call it in the form:\n",
    "\n",
    "<p style=\"text-align: center;\"> `tree.getiterator(tag=None)`  </p>\n",
    "\n",
    "If you don't specify what tag you want, it'll go through the first element it comes across in `tree` and then through its children and their children, etc. If you only want elements with a specific tag name, like `placeName`, you can pass it as the argument.\n",
    "\n",
    "Let's see how helpful `.getiterator()` can be! We'll call it on tree and print out the tag and attribute of each element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iterator = tree.getiterator()\n",
    "for element in iterator:\n",
    "    print(element.tag)\n",
    "    print(element.attrib)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3:** Using iterator and the information of the tags above, find the names of the defendant and the plaintiff by getting the text out of each element. You can either use a conditional to specify a tag and use `.tag` for some element, or specify a tag in `.getiterator()`.\n",
    "\n",
    "***Note:*** Because of the formatting in the XML file, the you should only get the plaintiff's first name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ... in ...:\n",
    "    if ...:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                  Samuel \n",
      "                  Davis\n",
      "               \n",
      "\n",
      "                  Catherine \n",
      "                  \n"
     ]
    }
   ],
   "source": [
    "#SOLUTION\n",
    "for element in iterator:\n",
    "    if element.tag == 'persName':\n",
    "        print(element.text)\n",
    "        \n",
    "#Samuel Davis\n",
    "#Catherine (no last name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are their names? *Write their names in this cell*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4:** How do you think we can use `.attrib` to find their names? You don't have to code anything, just explain how you can using `.attrib`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your response here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5:** Use `.getiterator()` again, and a new method, `.itertext()`, to get the entire text of the proceeding. Utilizing `.itertext()` method will return all inner text from every child.\n",
    "\n",
    "**Hint:** Find the tag that will return you the entire text of the trial and a way to join all the text from the file together.\n",
    "\n",
    "<sub>***Note:*** The text in these XML files are a little wonky, so if the printed text doesn't look formatted well, it's ok.</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ... in ...:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#SOLUTION\n",
    "for element in iterator:\n",
    "    if element.tag == \"p\":\n",
    "        print(''.join(list(element.itertext())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.6:** Since the textual data is pretty messy in the XML files of these proceedings, where do you think the data you need might be held and how might you go about extracting this data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your response here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Section 3: Web Scraping<a id='section 3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We learned how to get parse through one XML file. The Old Bailey API has a total of **197751** cases. Fortunately, we are only going to use the ones from 1754-1756 and 1824-1826, but that still only narrows the number of cases to 6506! \n",
    "\n",
    "Don't worry though, you're not going to manually download each case yourself. This is where web scraping comes into play. With web scraping, we can automate data collection to get all 6506 cases. \n",
    "\n",
    "Before we start scraping, we need to know how `requests` works. The `requests` library gets (`.get`!) you a response object from a web server and will automatically decode the content from the server, from which you can use `.text` to see the document! Requests through the Old Bailey API will return an XML file, which we can then write as a file and save.\n",
    "\n",
    "Let's take a look at all of the terms we can use to choose the specific cases we want. We use `.json()` here since the parameters are stored as a JSON object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "requests.get('http://www.oldbaileyonline.org/obapi/terms').json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wanted to explore the full list in your web browser, click [this link](https://www.oldbaileyonline.org/obapi/terms). \n",
    "\n",
    "Now that you've had a chance to look through some of the terms, let's see how to grab the specific XML files.\n",
    "\n",
    "Clicking the URL below returns a JSON object of the number of IDs and the frequency of each term in which every trial contains the term \"sheffield\" and the offence categrory \"deception\" from June 14th, 1847 onward. Also, each trial ID that satisfies the terms is returned; the count parameter in this case returns 10 trial IDs, but if left unspecified, the API will return a maximum count of 1000 IDs. \n",
    "\n",
    "https://www.oldbaileyonline.org/obapi/ob?term0=trialtext_sheffield&term1=offcat_deception&term2=fromdate_18470614&breakdown=offsubcat&count=10&start=0\n",
    "\n",
    "Although the terms for time are listed as numbers, the format for the term is\n",
    "`fromdate_(starting date)` and `todate_(ending date)` without the parentheses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1:** Use requests.get(...) to get the all trial IDs between the years 1754 and 1756 and return it as a JSON object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trials = ...\n",
    "trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#SOLUTION \n",
    "trials = requests.get('https://www.oldbaileyonline.org/obapi/ob?term0=fromdate_17540116&term1=todate_17561208&&start=0').json()\n",
    "trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets pick some trials from `trial['hits']`, so we have a list of IDs we can work with. \n",
    "\n",
    "**Question 3.2:** Select the first 10 trials by splicing through the list that we retrieved from the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_10 = ...\n",
    "first_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOLUTION\n",
    "first_10 = trials['hits'][:10]\n",
    "first_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the trial IDs from the previous cell, we are going to format the URL in a way so that we can get the XML file for each trial. In order to get the XML file using the Old Bailey API, we must follow this URL format:\n",
    "\n",
    "<p style=\"text-align: center;\">`http://www.oldbaileyonline.org/obapi/text?div=(enter trial ID here without parenthesis)`  </p>\n",
    "\n",
    "For example, http://www.oldbaileyonline.org/obapi/text?div=t16740429-1 gives you the link to the XML file of the first proceeding in the database.\n",
    "\n",
    "\n",
    "**Question  3.3:** Get the XML file of the first trial in first_10. A successful `.get` request returns `<Response [200]>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOLUTION\n",
    "url = 'http://www.oldbaileyonline.org/obapi/text?div={}'.format(first_10[0])\n",
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to see the XML format of the text! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the XML file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trial_number = 't17540116-11' #trial ID (make sure its a string)\n",
    "with open('data/old-bailey/old-bailey-' + trial_number + '.xml', 'w') as file:\n",
    "    file.write(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: Scraping all trials from 1754 - 1756\n",
    "\n",
    "Now that you know how to find the trial IDs for certain parameters as well as get an XML file using `requests.get(some_url)`, iterate through each ID in the list of trials (use `trials['hits']` for the list of IDs) we got from 1754-1756 earlier. You can choose how many trials you want to save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SOLUTION\n",
    "for trial in ...:\n",
    "    #format URL\n",
    "    \n",
    "    #get text from URL\n",
    "    \n",
    "    #save the file **store in data/old-bailey/file_name\n",
    "    \n",
    "    #one second pause so servers aren't overloaded\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SOLUTION\n",
    "for trial in trials['hits'][:30]:\n",
    "    #format URL\n",
    "    url =  'http://www.oldbaileyonline.org/obapi/text?div={}'.format(trial)\n",
    "    print(url)\n",
    "    #get text from URL\n",
    "    text = requests.get(url).text\n",
    "    #save the file\n",
    "    with open('data/old-bailey/old-bailey-' + trial + '.xml', 'w') as file:\n",
    "        file.write(text)\n",
    "    #one second pause so servers aren't overloaded\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check if you saved the XML files by executing the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ls data/old-bailey/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell will show you the XML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cat data/old-bailey/old-bailey-t17540116-1.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Section 4: Putting it all in a dataframe<a id='section 4'></a>\n",
    "\n",
    "Now that we have a bunch of XML files and know how to parse through them to extract data, let's put the data from the XML files into a dataframe. As you probably saw earlier from printing the text of the court proceeding, the text was incredibly messy. Feel free to process the text yourself, but specifically for this last section, we'll use the data from each attribute to put in our dataframe.\n",
    "\n",
    "**Question 4.1:** Complete the body of a function `table_of_cases`, which returns a dataframe with the \"type\" of data as a column label and the value from that attribute in that column. Make sure to account for cases that either won't have as many attributes as others (e.g. there are two defendants in one trial, but only one in the other). The body of the function is structured for you.\n",
    "\n",
    "**Tips:** Open up different trials to see all \"type\" keys in attributes. Which tag contains the attributes with information you can use? And how will you account for repeating \"type\" keys showing up repeatedly (e.g. surname, given, etc.) so that you don't replace the value you already have in the existing column with the same key? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def table_of_cases(xml_file_name):\n",
    "    #load file\n",
    "    file = ET.ElementTree(...)\n",
    "    #create an iterator object\n",
    "    iterate = ...\n",
    "    #create empty dataframe\n",
    "    table = ...\n",
    "    #create a possible index for repeating \"types\"\n",
    "    i = 1\n",
    "    for ... in ...:\n",
    "        if element.tag == ...:\n",
    "            #get attrib\n",
    "            t = ...\n",
    "            #get value of type\n",
    "            val = [...]\n",
    "            #labels of columns in table\n",
    "            label = list(...)\n",
    "            #change possible index to string\n",
    "            num = ...\n",
    "            #Implement conditional clauses to check if we already have\n",
    "            #the \"type\" as a column label. If there is, how\n",
    "            #can we make a unique label for the repeating column name?\n",
    "            if ... not in ...:\n",
    "                ...\n",
    "            #conditional clause 2\n",
    "            elif ... not in ...:\n",
    "                ...\n",
    "            #conditional clause 3\n",
    "            elif ... in ...:\n",
    "                ...\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SOLUTION\n",
    "def table_of_cases(xml_file_name):\n",
    "    file = ET.ElementTree(file = xml_file_name)\n",
    "    iterate = file.getiterator()\n",
    "    i = 1\n",
    "    table = pd.DataFrame()\n",
    "    for element in iterate:\n",
    "        if element.tag == \"interp\":\n",
    "            t = element.attrib['type']\n",
    "            val = [element.attrib['value']]\n",
    "            labels = list(table.columns.values)\n",
    "            num = str(i)\n",
    "            if t not in labels:\n",
    "                table[t] = val\n",
    "            elif t+num not in labels:\n",
    "                table[t+num] = val\n",
    "            elif t+num in labels:\n",
    "                num = str(i+1)\n",
    "                table[t+num] = val\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.2:** Now, use `table_of_cases` to load the attribute data from each XML file that you scraped. Load a blank dataframe so you can append the table of information after each call. Use the argument `ignore_index = True` in `.append` so that the indices will be formatted correctly.\n",
    "\n",
    "**Note:** Use the same file name format used when scraping these files and load from the correct directory, or else you won't be able to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table = ...\n",
    "for ...:\n",
    "    raw_data = ... #leave it as file name\n",
    "    data_to_table = ....\n",
    "    table = ...\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOLUTION\n",
    "table = pd.DataFrame()\n",
    "for i in trials['hits'][:30]:\n",
    "    raw_data = 'data/old-bailey/old-bailey-'+ i +'.xml'\n",
    "    data = table_of_cases(raw_data)\n",
    "    table = table.append(data, ignore_index=True)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! Now you know how to parse through XML files using XPath and web scrape using the `requests` library! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography\n",
    "\n",
    " - All files from Old Bailey API - https://www.oldbaileyonline.org/obapi/\n",
    " - ElementTree information adapted from Driscoll, Mike. (2013, April). Python 101 â€“ Intro to XML Parsing with ElementTree.\n",
    " https://www.blog.pythonlibrary.org/2013/04/30/python-101-intro-to-xml-parsing-with-elementtree/\n",
    "\n",
    " - Web Scraping code adapted from MEDST-250 Notebook developed by Tejas Priyadarshan.\n",
    " https://github.com/ds-modules/MEDST-250/tree/master/04%20-%20XML_Day_1\n",
    " \n",
    " - Image source from https://www.researchgate.net/publication/257631377_Efficient_XML_Path_Filtering_Using_GPUs\n",
    "\n",
    "----\n",
    "Notebook developed by: Jason Jiang\n",
    "\n",
    "Data Science Modules: http://data.berkeley.edu/education/modules"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
