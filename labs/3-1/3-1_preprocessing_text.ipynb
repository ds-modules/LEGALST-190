{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [LEGALST-190] Preprocessing Text - Lab 3-1\n",
    "\n",
    "---\n",
    "\n",
    "This lab will provide an introduction to manipulating strings and chunking sentences.\n",
    "\n",
    "*Estimated Time: 30-40 minutes*\n",
    "\n",
    "---\n",
    "\n",
    "### Topics Covered\n",
    "- How to tokenize text\n",
    "- How to stem text\n",
    "- How to chunk text\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "[The Data](#section data)<br>\n",
    "\n",
    "1 - [Tokenization](#section 1)<br>\n",
    "\n",
    "2 - [Stemming](#section 2)<br>\n",
    "\n",
    "3 - [Chunking](#section 3)<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): nltk in /Users/tianqin/anaconda3/lib/python3.5/site-packages\n",
      "\u001b[33mYou are using pip version 8.1.2, however version 9.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## The Data <a id='data'></a>\n",
    "\n",
    "\n",
    "In this notebook, you'll be working with the text of each countryâ€™s statement from the General Debate in annual sessions of the United Nations General Assembly. This dataset is separated by country, session and year and tagged for each, and has over forty years of data from different countries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the below cells and take a look at a sample of the data that we'll be working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  pip install [options] [-e] <vcs project url> ...\n",
      "  pip install [options] [-e] <local project path> ...\n",
      "  pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: --update\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'core'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4d431afe8316>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pip install pandas --update'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'unzip \"../data/un-general-debates.zip\"'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../data/un-general-debates.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig_init\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\api.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnotna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnotnull\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategorical\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_eng_float_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m from pandas.core.index import (Index, CategoricalIndex, Int64Index,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validators\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvalidate_kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithms\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moption_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'core'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "!unzip \"../data/un-general-debates.zip\"\n",
    "data = pd.read_csv(\"../data/un-general-debates.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'un-general-debates.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9dbc2d90fc65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"un-general-debates.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'un-general-debates.csv'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "data = list(csv.reader(open(\"un-general-debates.csv\", 'r')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['session', 'year', 'country', 'text'],\n",
       " ['44',\n",
       "  '1989',\n",
       "  'MDV',\n",
       "  \"\\ufeffIt is indeed a pleasure for me and the members of my delegation to extend to Ambassador Garba our sincere congratulations on his election to the presidency of the forty-fourth session of the General Assembly. His election to this high office is a well-deserved tribute to his personal qualities and experience. I am fully confident that under his able and wise leadership the Assembly will further consolidate the gains achieved during the past year.\\nMy delegation associates itself with previous speakers in expressing its appreciation of the dedicated efforts of his predecessor, His Excellency Mr. Dante Caputo, for the exemplary manner in which he discharged his duties as President of the forty-third session of the General Assembly.\\nAs in previous years, my delegation wishes to note its satisfaction with and gratitude for the assiduous and unrelenting efforts exerted by the Secretary-General of the United Nations in the cause of peace and international harmony. We pay a tribute to him for his untiring efforts to promote conditions conducive to the realization of the noble principles enshrined in the Charter of the United Nations, we praise and congratulate him on the successes the Organization has achieved in recent years. More particularly we praise him for the renewed faith and regeneration of confidence in the Organization and its ability to Play an instrumental role in the peaceful settlement of disputes.  \\nToday we find ourselves at an important crossroads. Recent years have witnessed a welcome positive change in the international political climate. The confrontational tone evident in super-Power relations not too long ago continues to show signs of thawing. At the same time,, a number of regional and sub regional conflicts have taken momentous strides towards resolution. Many more protracted conflicts show signs of hope and movement. Though one might argue that the present situation continues to be delicate, the process made can hardly escape notice and is indeed worthy of recognition. \\nDevelopments in southern Africa, and more particularly in Namibia with regard to the implementation of the United Nations independence plan, are welcome signals of hope, but amidst the hopes there are still dark reminders of the precariousness of global political reconciliation. A number of problems remain unsolved and several of these, such as the conflicts in the Middle East, continue to simmer.\\nWe are therefore at an important crossroads. We feel that there is enough good will to set in motion the process of evolution towards peace and stability. We see signs that the human intellect is resourceful enough to devise ideas that are conducive to our survival. Fresh concepts of peace and security have gained currency, but at the same time we continue to live under the dark shadow of nuclear devices. The proliferation of nuclear weapons, both horizontally and vertically, is a tragic reminder of the difficulties and obstacles which stand between mankind and lasting peace.\\nOn the economic front hard choices need to be made. The 1980s have witnessed one of the longest spells of growth for the industrialized countries, while the situation in the South, particularly in the least developed countries, continues to deteriorate. Benefits of trade continue to be disproportionate. Commodity prices have not regained their value in real terms. Aid flows continue to be inadequate. The debt burden borne by many third world countries is stifling economic growth and efforts for development, causing political instability. The link between economic development and the environment has recently been recognized and it is encouraging to note the high profile given to environmental issues at the Paris summit meeting of the Group of Seven in July this year, in this regard, it is of particular interest that there is an increasing awareness and acceptance of the fact that certain technologies have a deleterious effect on the environment. The question is how these technologies can be replaced through a global programme of co-operation.\\nNo single fact, no single object, defines our moment in civilization more than does the existence of large nuclear arsenals. we have the horrible capacity to destroy our planet several times other, either by accident or by design. Nuclear weapons instil fear and beget mistrust and insecurity. They have a remarkable tendency to set hostile relations in concrete. They aggravate the security dilemma of states and perpetuate a confliction mode of behaviour. This, therefore, fuels the arms race and defence budgets soar while expenditures that are benevolent tend to plummet. \\nThe UN Conference on the relationship between disarmament and development served as a timely reminder of the opportunity costs of armaments, both nuclear and conventional. However the opportunity cost of nuclear weaponry is not only development. The international political climate and the security perceptions of states, as well as the environment, are actual and potential sacrifices to\\nnuclear weapons. Furthermore. the potential horizontal proliferation of nuclear weapons issues the stark and grim warning that regional rivalries would be on an ever shorter fuse and that cataclysm would be that much closer.\\nIt is in view of these strong objections  to nuclear weapons and their Proliferation and deployment that my delegation has consistently and strongly supported United Nations calls for disarmament.\\nThe confidence that can he derived from genuine arms reduction has a pervasive effect on the security environment. The transition that many of the world's conflict, are making towards negotiations and understanding owes a great deal to improved relations between the super-Powers, which were themselves in part inspired by the historic arms reduction agreement of December 1987 for this reason -at Maldives has always supported all efforts with a view to general and complete disarmament, including the total elimination of chemical and bacteriological weapons and reduction in conventional armaments. We also believe that nuclear-weapon-free zones and zones of peace could inspire trust, good Will and operation among states, transforming into secure communities contributing to global peace and security. We therefore support calls for the establishment of nuclear-weapon-free zones and zones of peace. \\nI express my delegation's fullest support for the people of Namibia, with our Namibia achieved their independence.  Apartheid is an affront to mankind and a crime against humanity. No amount of tinkering with it can placate the sense of outrage and indignation felt by the world community for this immoral practice. No amount of cosmetic change can restore Justice and dignity to the oppressed majority in South Africa. Maldives express our solidarity with the oppressed majority in South Africa in their struggle against apartheid. We condemn unequivocally the system of apartheid and condemn Pretoria regime for its continued defiance of the UN resolutions.  \\nBy far the greatest conflict in our time has been and continues to be the conflict in the Middle East. At the heart of this conflict is the question of Palestine. However, it is only in recent years that the Palestinian issue has evoked even a reasoned amount of concern in some key States. The search for peace continues to be frustrated by the hard-line and obstinate policies of Israel. Meanwhile, the situation in the occupied territories continues to deteriorate. The 22 month long intifadah emphasizes the intensity of the situation posed by Zionist occupation of Palestine and other Arab territories, including Jerusalem.\\nThe Government of Maldives strongly condemns the use of brutal force and the blatant abuse of human rights by Israel against the Palestinian people in the occupied territories. We also deplore the continued defiance by Israel of United Nations resolutions and its violation of international law and all norms of civilized behaviour. We reiterate our full support and solidarity with the people of Palestine in their just struggle for self-determination and independence. We therefore welcome the overwhelming international support for the uprising, which is being viewed as the just and valiant struggle of the Palestinian people for the restoration of their inalienable rights. We extend our whole-hearted support to the proposal for an early convening of an international conference on the Middle East with the full and independent participation of Palestine.\\nThe situation in Lebanon remains volatile. The civil war, now in its fifteenth year, continues to take an increasing toll of human life. We fervently hope that, with the developments taking place in the region and elsewhere, the question of Lebanon will be solved in a manner which will restore its independence and national integrity, and alleviate the sufferings of its people. We welcome the efforts undertaken by the members of the Arab league, both past and present, to resolve the situation in Lebanon and we request the international community to give their support to the people of Lebanon in their efforts to solve their problems.\\nOn a more hopeful note, we are pleased that, contrary to some early pessimistic assessments, the cease-fire agreed on between Iran and Iraq in the Gulf has held firm, indicating the sincerity of the parties to the conflict. We welcome the commitments undertaken by them to resolve the conflict by peaceful means. In particular, we applaud the efforts of the United Nations Secretary-General for the resolution of this conflict and urge both parties to maintain the momentum of peace created and envisaged by the cease-fire. \\nWhile we welcome the positive developments in Afghanistan - I refer to the withdraw of foreign troops - we regret that the situation has not been completely settled. We reiterate our call upon all parties concerned to adhere to the provisions of the Geneva Agreements in order not to frustrate the prevailing opportunities for a just and lasting solution to the problem. We urge the international community to provide humanitarian and economic assistance for the relief and rehabilitation of refugees, as well as for the long-term reconstruction of that ravaged country.  \\nPositive strides have been taken towards the solution of the Kampuchean problem. We welcome the withdraw of the Vietnamese troops and we appreciate the diplomatic efforts to obtain a comprehensive and lasting solution to the dispute including the Jakarta informal meeting as well as the international conference in Paris. However, realizing the delicacy of the current situation, we call upon all parties concerned to exercise restraint. \\nThe process of reunification of peoples should be through peaceful means and by the creation of conditions conducive to reconciliation, peace and stability among those sharing the same aspirations. We remain optimistic about the prospects for peaceful national reconciliation in the Korean peninsula. The good office of the UN could be utilized in these peace negotiations.  \\nAnother issue that needs our attention is the situation in Cyprus. That prolonged inter-communal dispute should be solved urgently, with due regard to the national integrity of the nation and the aspirations of its peoples. We welcome the recent high-level contacts between the two communities and hope that the revived inter-communal dialogue will lead to inter-communal reconciliation on the basis of equality and integrity for both communities. We commend the tireless and sincere efforts of the Secretary-General in searching for a settlement to the conflict.\\nAs I have already noted, the world economic situation continues to be bleak for the developing countries. Their situation has been worsened by the limited of aid since the early 1980s, rampant domestic inflation, crippling debts and the exorbitant burden of debt-servicing. The situation is aggravated by their falling share in international trade, by persistent negative trends in the terms of trade, owing to protectionism, and by the upsurge in unilateralism and other practices that jeopardize the multilateral nature of trade. It is regrettable that, on the whole, despite recent measures whereby the resources of the international finance institutions have been increased by the plans of some of the most developed countries to recycle part of their surplus into the developing countries, the internationally agreed target of 0.7 per cent of gross national product (GNP) as official development assistance has not been met. Moreover, as regards the least developed countries, which continue to register negative growth rates, the official development assistance target of 0.15 per cent of GNP has not been met either.\\nEconomic insecurity is not the only visible threat facing many of us in the world today. Indeed, we consider the environment to be one of the most important aspects of the quality of life that we have to address now in our quest for economic and industrial development. We welcome the proposed United Nations conference on environment and development and regard the event as a valuable opportunity which should be fully utilized to promote a comprehensive approach to the environmental problems related to the development activities of mankind.\\nWhile serious efforts are being made at global, regional and national levels to protect the environment, my delegation is particularly concerned about the effects of the degradation of the environment, especially the depletion of the ozone layer and the consequent global warming and rise in sea level. Maldives is a low-lying archipelagic State, entirely dependent upon its surrounding seas. Any degradation of the marine ecosystem, or any rise in the mean sea level, is a matter of grave concern to the Maldives, it will be recalled that two years ago we witnessed the fury of tidal eruptions, which caused extensive damage, with the assistance of friendly countries, we have embarked upon a programme of protecting the populated islands from possible natural calamities. Tidal waves, hurricanes and typhoons are increasingly frequent phenomena, and today there is a greater awareness that man's tampering with the environment and certain technologies inimical to the environment do have a direct bearing on the behaviour of the global weather system.\\nMaldives therefore strongly supports the call for environmental preservation and is already a party to the Vienna Convention for the Protection of the Ozone Layer and the Montreal Protocol on Substances that Deplete the Ozone Layer. Our interest in the issue continues undiminished, and we welcome the universal interest that has been expressed in the preservation of the environment. I should like also to mention that in November this year the Maldives will host a conference of small States on sea-level rise. We are confident that the conference will contribute to the global efforts in addressing this important issue.\\nIt is an old and true maxim that the best indicator of the strength and stability of an international security system or political order is the survival of its weakest members. That being the case, and in view of the implications, the ever-increasing dangers of terrorism and mercenarism to the sovereignty of small and weak States are appalling.\\nTerrorism is not simply a minor irritant to anybody - least of all, to the small nations whose sovereignty is not only held hostage but can be easily usurped. The very existence of this possibility in the first place does not augur well for the security of the international community. The cherished principles that have so long contributed to the survival of the present State system and that are indispensable values of our global civilization are at stake. Today it may be we, the small States, whose sovereignty can be robbed by a handful of mercenaries or a gang of bounty hunters. Tomorrow it could be the larger countries, which, even at present, face some erosion of their sovereignty and security by similar acts. The difference is that when a small State is subjected to a terrorist onslaught or an invasion by mercenaries the consequences can be irreversible, both in political and in economic terms. We in the Maldives were close to becoming the victim of such a dastardly attempt last November.\\nIt is evident that peoples engaging in acts of terrorism and mercenarism, which endanger the sovereignty and territorial integrity of States, need to be deterred. The security of small States is too weak to be taken care of by mere self-help. The implications that efforts to strengthen their own security have for the prospects of economic development through the severe, if at all affordable, opportunity costs and the impact on social and political values, as well as the long-term implications for the sustenance of democracy in a militarised society, are negative. By requesting the inclusion on the agenda of the Assembly of an item related to the protection and security of small States, we sought to highlight the issue that I have just mentioned. We brought the issue to this forum not because we are unwilling to defend our values, nor have we taken it up here because our peoples lack valour. \\nSmall States do have as friends States that can assist, and have assisted, in strengthening their security. While we are grateful for the sense of duty that these friends have shown, it is with regret that we note that bilateral security arrangements in the international system have not yet evolved to a level of maturity whereby the interests of the weaker partner can be safeguarded. Nor are the socio-political identity of the weaker State and the principle of sovereign equality strong enough to be impervious to the possible vicissitudes of unequal relationships. Moreover, our political systems continue to be afflicted by misconceptions which can distort actions taken with the best of intentions. Consequently, the greater the power differential, the greater the propensity to misconceptions and the more hapless the predicament of the weaker parties. It is for this reason that we believe that multilateral frameworks are the most feasible nodes of a sound security mechanism for the weakest Members of the Organization, even if the actual support or assistance in a given situation is rendered at a regional or bilateral level.\\nAs I noted earlier, it is my humble opinion that we are at a pivotal point, an important crossroads in our global political development. It is our belief that we are at a particularly auspicious moment in history to forge ahead in strengthening the norms of our global political and security systems. Thus it is our sincere hope that the Organization will take a similar momentous step, a leap forward in ushering in a new era of security for the small States. We trust that this critical step will be taken to safeguard the principles which are espoused by the Organization and on which the survival of a large number of this community depends.\\n\"]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization  <a id='section 1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization is defined as <b>the process of segmenting running text into words and sentences</b>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why do we need to tokenize text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Electronic text is a linear sequence of symbols. Before any processing is to be done, text needs to be segmented into linguistic units, and this process is called tokenization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We usually look at grammar and meaning at the level of words, related to each other within sentences, within each document. So if we're starting with raw text, we first need to split the text into sentences, and those sentences into words -- which we call \"tokens\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might imagine that the easiest way to identify sentences is to split the document at every period '.', and to split the sentences using white space to get the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿It is indeed a pleasure for me and the members of my delegation to extend to Ambassador Garba our sincere congratulations on his election to the presidency of the forty-fourth session of the General Assembly\n",
      "\n",
      " His election to this high office is a well-deserved tribute to his personal qualities and experience\n",
      "\n",
      " I am fully confident that under his able and wise leadership the Assembly will further consolidate the gains achieved during the past year\n",
      "\n",
      "\n",
      "My delegation associates itself with previous speakers in expressing its appreciation of\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using the split function to create tokens\n",
    "paragraph = data[1][3][:540]\n",
    "sentences = paragraph.split(\".\")\n",
    "for s in sentences:\n",
    "    print(s + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then to split sentences further into words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What', 'kind', 'of', 'patterns', 'do', 'you', 'see', 'in', 'this', 'graph?']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"What kind of patterns do you see in this graph?\"\n",
    "tokens = sentence.split(\" \")\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular expressions allow us to better tokenzie text. Run the example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'has', '', 'weird', '', '', '', '', 'spacing', 'issues']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "s1 = \"this has  weird     spacing issues\"\n",
    "s1.split(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we split a sentence by <b>one space</b>, some spaces above are also being treated as tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'has', 'weird', 'spacing', 'issues']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split using regular expression\n",
    "re.split(r'\\s+', s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\\s\" denotes a space character, and + sign means one or more. Thus, \\s+ means one or more spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brazil', 'china', 'france', 'australia']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2 = \"brazil4china2france5australia\"\n",
    "re.split(r'[0-9]', s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we are splitting up the sentence at each number. Regular expression provides an easy and clean way to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to find all the words that are of length 5 in the below sentence.\n",
    "\n",
    "{5} denotes that there are exactly 5 of whatever precedes it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' topic ', ' links ', ' other ']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3 = \"A well-written encyclopedia article identifies a notable encyclopedic topic, summarizes that topic comprehensively, contains references to reliable sources, and links to other related topics\"\n",
    "re.findall(r'\\s+[a-z]{5}\\s+', s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two things happening here:\n",
    "\n",
    "1. `[` and `]` do not mean 'bracket'; they are special characters which mean 'anything of this class'\n",
    "2. we've only matched one letter each\n",
    "\n",
    "re is flexible about how you specify numbers - you can match none, some, a range, or all repetitions of a sequence or character class.\n",
    "\n",
    "character | meaning\n",
    "----------|--------\n",
    "`{x}`     | exactly x repetitions\n",
    "`{x,y}`   | between x and y repetitions\n",
    "`?`       | 0 or 1 repetition\n",
    "`*`       | 0 or many repetitions\n",
    "`+`       | 1 or many repetitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question</b>: find all words of length 8 in speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech = data[1][3]\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "re is powerful but we'll stop there, because NLTK provides handy classes to do this for us:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK (Natural Language Toolkit) is a platform for building Python programs to work with human language data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# run the below commented command if error\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffIt is indeed a pleasure for me and the members of my delegation to extend to Ambassador Garba our sincere congratulations on his election to the presidency of the forty-fourth session of the General Assembly.',\n",
       " 'His election to this high office is a well-deserved tribute to his personal qualities and experience.',\n",
       " 'I am fully confident that under his able and wise leadership the Assembly will further consolidate the gains achieved during the past year.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = nltk.sent_tokenize(speech)\n",
    "sents[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['At',\n",
       " 'eight',\n",
       " \"o'clock\",\n",
       " 'on',\n",
       " 'Thursday',\n",
       " 'morning',\n",
       " 'Arthur',\n",
       " 'did',\n",
       " \"n't\",\n",
       " 'feel',\n",
       " 'very',\n",
       " 'good',\n",
       " '.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s4 = \"At eight o'clock on Thursday morning Arthur didn't feel very good.\"\n",
    "nltk.word_tokenize(s4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk recognized that \"o'clock\" is one word and separated \"didn't\" into \"did\" and \"n't\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more complicated metrics, it's easier to use NLTK's classes and methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 270),\n",
       " ('of', 165),\n",
       " ('.', 121),\n",
       " ('and', 110),\n",
       " (',', 109),\n",
       " ('to', 95),\n",
       " ('in', 74),\n",
       " ('that', 48),\n",
       " ('a', 47),\n",
       " ('is', 40)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(speech)\n",
    "fd = nltk.collocations.FreqDist(tokens)\n",
    "fd.most_common()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of classifying words into their parts of speech and labeling them accordingly is known as part-of-speech tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('indeed', 'RB'),\n",
       " ('a', 'DT'),\n",
       " ('pleasure', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('me', 'PRP'),\n",
       " ('and', 'CC')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged = nltk.pos_tag(tokens[2:8])\n",
    "tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common step in text analysis is to remove noise. *However*, what you deem \"noise\" is not only very important but also dependent on the project at hand. For the purposes of today, we will discuss two common categories of strings often considered \"noise\". \n",
    "\n",
    "- Punctuation: While important for sentence analysis, punctuation will get in the way of word frequency and n-gram analyses. They will also affect any clustering on topic modeling.\n",
    "\n",
    "- Stopwords: Stopwords are the most frequent words in any given language. Words like \"the\", \"a\", \"that\", etc. are considered not semantically important, and would also skew any frequency or n-gram analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question</b> Write a function below that takes a string as an argument and returns a list of words without punctuation or stopwords.\n",
    "\n",
    "`punctuation` is a list of punctuation strings, and we have created the list `stop_words` for you.\n",
    "\n",
    "Hint: first you'll want to remove punctuation, then tokenize, then remove stop words. Make sure you account for upper and lower case!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rem_punc_stop(text):\n",
    "    \n",
    "    from string import punctuation\n",
    "    from nltk.corpus import stopwords\n",
    "    \n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    \n",
    "    punc_removed = \"\"\n",
    "    for i in text:\n",
    "        if i not in punctuation:\n",
    "            punc_removed += i\n",
    "        else:\n",
    "            punc_removed += \" \"\n",
    "            \n",
    "    tokens = nltk.word_tokenize(punc_removed)\n",
    "    noise_free = []\n",
    "    for token in tokens:\n",
    "        if token not in stop_words:\n",
    "            noise_free += [token]\n",
    "    return noise_free"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can rerun our frequency analysis without the noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('We', 25),\n",
       " ('The', 23),\n",
       " ('security', 16),\n",
       " ('international', 14),\n",
       " ('situation', 13),\n",
       " ('efforts', 13),\n",
       " ('development', 11),\n",
       " ('political', 11),\n",
       " ('peace', 11),\n",
       " ('environment', 11)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_reduced = rem_punc_stop(speech)\n",
    "fd_reduced = nltk.collocations.FreqDist(tokens_reduced)\n",
    "fd_reduced.most_common()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our analysis is much more informational and revealing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming <a id='section 2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In NLP it is often the case that the specific form of a word is not as important as the idea to which it refers. For example, if you are trying to identify the topic of a document, counting 'running', 'runs', 'ran', and 'run' as four separate words is not useful. Reducing words to their stems is a process called stemming.\n",
    "\n",
    "A popular stemming implementation is the Snowball Stemmer, which is based on the Porter Stemmer. Its algorithm looks at word forms and does things like drop final 's's, 'ed's, and 'ing's.\n",
    "\n",
    "Just like the tokenizers, we first have to create a stemmer object with the language we are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball = nltk.SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can try stemming some words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball.stem('running')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball.stem('eats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'embarass'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball.stem('embarassed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Snowball is a very fast algorithm, but it has a lot of edge cases. In some cases, words with the same stem are reduced to two different stems or two different words are reduced to the same stem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('cylind', 'cylindr')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball.stem('cylinder'), snowball.stem('cylindrical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('vacat', 'vacat')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball.stem('vacation'), snowball.stem('vacate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking<a id='section 3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to work with larger segments of text than single words (but still smaller than a sentence). For instance, in the sentence \"The black cat climbed over the tall fence\", we might want to treat \"The black cat\" as one thing (the subject), \"climbed over\" as a distinct act, and \"the tall fence\" as another thing (the object). The first and third sequences are noun phrases, and the second is a verb phrase.\n",
    "\n",
    "We can separate these phrases by \"chunking\" the sentence, i.e. splitting it into larger chunks than individual tokens. This is also an important step toward identifying entities, which are often represented by more than one word. You can probably imagine certain patterns that would define a noun phrase, using part of speech tags. For instance, a determiner (e.g. an article like \"the\") could be concatenated onto the noun that follows it. If there's an adjective between them, we can include that too.\n",
    "\n",
    "To define rules about how to structure words based on their part of speech tags, we use a grammar (in this case, a \"chunk grammar\"). NLTK provides a RegexpParser that takes as input a grammar composed of regular expressions. The grammar is defined as a string, with one line for each rule we define. Each rule starts with the label we want to assign to the chunk (e.g. NP for \"noun phrase\"), followed by a colon, then an expression in regex-like notation that will be matched to tokens' POS tags.\n",
    "\n",
    "We can define a single rule for a noun phrase like this. The rule allows 0 or 1 determiner, then 0 or more adjectives, and finally at least 1 noun. (By using 'NN.*' as the last POS tag, we can match 'NN', 'NNP' for a proper noun, or 'NNS' for a plural noun.) If a matching sequence of tokens is found, it will be labeled 'NP'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grammar = \"NP: {<DT>?<JJ>*<NN.*>+}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a chunk parser object by supplying this grammar, then use it to parse a sentence into chunks. The sentence we want to parse must already be POS-tagged, since our grammar uses those POS tags to identify chunks. Let's try this on the second sentence of the speech we generated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP H/NNP i/NN)\n",
      "  s/VBP\n",
      "  (NP  /JJ e/NN l/NN e/NN)\n",
      "  c/VBP\n",
      "  (NP t/NN i/NN)\n",
      "  o/VBP\n",
      "  (NP n/JJ  /NNP t/NN o/NN  /NNP t/NN h/NN)\n",
      "  i/JJ\n",
      "  s/VBP\n",
      "  (NP  /JJ h/NN i/NN)\n",
      "  g/VBP\n",
      "  (NP h/NN  /NNP)\n",
      "  o/VBZ\n",
      "  (NP f/JJ f/NN i/NN)\n",
      "  c/VBP\n",
      "  (NP e/NN  /NN i/NN)\n",
      "  s/VBP\n",
      "   /PDT\n",
      "  (NP a/DT  /JJ w/NN e/NN l/NN)\n",
      "  l/SYM\n",
      "  -/:\n",
      "  (NP d/NN e/NN s/NN e/NN r/NN v/NN e/NN d/NN  /NNP t/NN r/NN i/NN)\n",
      "  b/VBP\n",
      "  (NP u/JJ t/NN e/NN  /NNP t/NN o/NN  /NNP h/NN i/NN)\n",
      "  s/VBP\n",
      "  (NP  /JJ p/NN e/NN r/NN s/NN o/NN)\n",
      "  n/IN\n",
      "  (NP a/DT l/NN  /NNP q/NN)\n",
      "  u/VBD\n",
      "  (NP a/DT l/NN i/NN)\n",
      "  t/VBP\n",
      "  (NP i/NN)\n",
      "  e/VBP\n",
      "  s/JJ\n",
      "   /FW\n",
      "  (NP a/DT n/JJ d/NN  /NNP e/NN x/NNP p/NN e/NN r/NN i/NN)\n",
      "  e/VBP\n",
      "  (NP n/JJ c/NN e/NN)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "from nltk import RegexpParser\n",
    "\n",
    "cp = RegexpParser(grammar)\n",
    "\n",
    "sent_tagged = nltk.pos_tag(sents[1])\n",
    "sent_chunked = cp.parse(sent_tagged)\n",
    "\n",
    "print(sent_chunked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we called print() on this chunked sentence, it printed out a nested list of nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.tree.Tree"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sent_chunked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree object has a number of methods we can use to interact with its components. For instance, we can use the method draw() to see a more graphical representation. This will open a separate window.\n",
    "\n",
    "The tree is pretty flat, because we defined a grammar that only grouped words into non-overlapping noun phrases, with no additional hierarchy above them. This is sometimes referred to as \"shallow parsing\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_chunked.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Notebook developed by: X,X,X\n",
    "\n",
    "Data Science Modules: http://data.berkeley.edu/education/modules\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
