{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [LEGALST-190] Preprocessing Text - Lab 3-1\n",
    "\n",
    "---\n",
    "\n",
    "This lab will provide an introduction to manipulating strings and chunking sentences.\n",
    "\n",
    "*Estimated Time: 30-40 minutes*\n",
    "\n",
    "---\n",
    "\n",
    "### Topics Covered\n",
    "- How to tokenize text\n",
    "- How to stem text\n",
    "- How to chunk text\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "[The Data](#section data)<br>\n",
    "\n",
    "1 - [Tokenization](#section 1)<br>\n",
    "\n",
    "2 - [Stemming](#section 2)<br>\n",
    "\n",
    "3 - [Chunking](#section 3)<br>\n"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): nltk in /Users/tianqin/anaconda3/lib/python3.5/site-packages\n",
      "\u001b[33mYou are using pip version 8.1.2, however version 9.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk"
   ]
  },
  {
=======
>>>>>>> 2879df7a58ceecdf969da14559dc60490990c64b
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## The Data <a id='data'></a>\n",
    "\n",
    "\n",
    "In this notebook, you'll be working with the text of each country’s statement from the General Debate in annual sessions of the United Nations General Assembly. This dataset is separated by country, session and year and tagged for each, and has over forty years of data from different countries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the below cells and take a look at a sample of the data that we'll be working with."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 1,
>>>>>>> 2879df7a58ceecdf969da14559dc60490990c64b
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"data/un-general-debates.zip\", compression='zip')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 2,
>>>>>>> 2879df7a58ceecdf969da14559dc60490990c64b
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>year</th>\n",
       "      <th>country</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>1989</td>\n",
       "      <td>MDV</td>\n",
       "      <td>﻿It is indeed a pleasure for me and the member...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>1989</td>\n",
       "      <td>FIN</td>\n",
       "      <td>﻿\\nMay I begin by congratulating you. Sir, on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>1989</td>\n",
       "      <td>NER</td>\n",
       "      <td>﻿\\nMr. President, it is a particular pleasure ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>1989</td>\n",
       "      <td>URY</td>\n",
       "      <td>﻿\\nDuring the debate at the fortieth session o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44</td>\n",
       "      <td>1989</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>﻿I should like at the outset to express my del...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session  year country                                               text\n",
       "0       44  1989     MDV  ﻿It is indeed a pleasure for me and the member...\n",
       "1       44  1989     FIN  ﻿\\nMay I begin by congratulating you. Sir, on ...\n",
       "2       44  1989     NER  ﻿\\nMr. President, it is a particular pleasure ...\n",
       "3       44  1989     URY  ﻿\\nDuring the debate at the fortieth session o...\n",
       "4       44  1989     ZWE  ﻿I should like at the outset to express my del..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization  <a id='section 1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization is defined as <b>the process of segmenting running text into words and sentences</b>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why do we need to tokenize text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Electronic text is a linear sequence of symbols. Before any processing is to be done, text needs to be segmented into linguistic units, and this process is called tokenization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We usually look at grammar and meaning at the level of words, related to each other within sentences, within each document. So if we're starting with raw text, we first need to split the text into sentences, and those sentences into words -- which we call \"tokens\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might imagine that the easiest way to identify sentences is to split the document at every period '.', and to split the sentences using white space to get the words."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 3,
>>>>>>> 2879df7a58ceecdf969da14559dc60490990c64b
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿It is indeed a pleasure for me and the members of my delegation to extend to Ambassador Garba our sincere congratulations on his election to the presidency of the forty-fourth session of the General Assembly\n",
      "\n",
      " His election to this high office is a well-deserved tribute to his personal qualities and experience\n",
      "\n",
      " I am fully confident that under his able and wise leadership the Assembly will further consolidate the gains achieved during the past year\n",
      "\n",
      "\n",
      "My delegation associates itself with previous speakers in expressing its appreciation of the dedicated efforts of his predecessor, His Excellency Mr\n",
      "\n",
      " Dante Caputo, for the exemplary manner in which he discharged his duties as President of the forty-third session of the General Assembly\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using the split function to create tokens\n",
    "paragraph = data['text'][0]\n",
    "sentences = paragraph.split(\".\")\n",
    "for s in sentences[:5]:\n",
    "    print(s + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then to split sentences further into words."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 4,
>>>>>>> 2879df7a58ceecdf969da14559dc60490990c64b
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What', 'kind', 'of', 'patterns', 'do', 'you', 'see', 'in', 'this', 'graph?']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"What kind of patterns do you see in this graph?\"\n",
    "tokens = sentence.split(\" \")\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll stop here as NLTK provides handy tools for us to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "Regular expressions allow us to better tokenzie text. Run the example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'has', '', 'weird', '', '', '', '', 'spacing', 'issues']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "s1 = \"this has  weird     spacing issues\"\n",
    "s1.split(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we split a sentence by <b>one space</b>, some spaces above are also being treated as tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'has', 'weird', 'spacing', 'issues']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split using regular expression\n",
    "re.split(r'\\s+', s1)"
=======
    "### NLTK"
>>>>>>> 2879df7a58ceecdf969da14559dc60490990c64b
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK (Natural Language Toolkit) is a platform for building Python programs to work with human language data"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brazil', 'china', 'france', 'australia']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2 = \"brazil4china2france5australia\"\n",
    "re.split(r'[0-9]', s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we are splitting up the sentence at each number. Regular expression provides an easy and clean way to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to find all the words that are of length 5 in the below sentence.\n",
    "\n",
    "{5} denotes that there are exactly 5 of whatever precedes it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
=======
   "execution_count": 5,
   "metadata": {},
>>>>>>> 2879df7a58ceecdf969da14559dc60490990c64b
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\keeley\\anaconda3\\lib\\site-packages\n",
      "Requirement already satisfied: six in c:\\users\\keeley\\anaconda3\\lib\\site-packages (from nltk)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech = data[1][3]\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "re is powerful but we'll stop there, because NLTK provides handy classes to do this for us:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK (Natural Language Toolkit) is a platform for building Python programs to work with human language data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# run the below commented command if error\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
=======
   "execution_count": 6,
   "metadata": {},
>>>>>>> 2879df7a58ceecdf969da14559dc60490990c64b
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"\\ufeffI should like at the outset to express my delegation's satisfaction and pleasure at your election, Sir, to the presidency of the General Assembly at its forty-fourth session.\",\n",
       " 'The unanimity of that decision reflects not only your own distinguished record as Foreign Minister and Permanent Representative of your country to the United Nations but also the prestige of your country, Nigeria, of which all of us in Africa are proud.',\n",
       " 'The outgoing President of the General Assembly, Mr. Dante Caputo of Argentina, shouldered the responsibility of his office with distinction in a momentous and difficult year.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create sentence tokens\n",
    "speech = data['text'][4]\n",
    "sents = nltk.sent_tokenize(speech)\n",
    "sents[:3]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
=======
   "execution_count": 7,
>>>>>>> 2879df7a58ceecdf969da14559dc60490990c64b
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['At',\n",
       " 'eight',\n",
       " \"o'clock\",\n",
       " 'on',\n",
       " 'Thursday',\n",
       " 'morning',\n",
       " 'Arthur',\n",
       " 'did',\n",
       " \"n't\",\n",
       " 'feel',\n",
       " 'very',\n",
       " 'good',\n",
       " '.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s4 = \"At eight o'clock on Thursday morning Arthur didn't feel very good.\"\n",
    "nltk.word_tokenize(s4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk recognized that \"o'clock\" is one word and separated \"didn't\" into \"did\" and \"n't\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more complicated metrics, it's easier to use NLTK's classes and methods."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
=======
   "execution_count": 8,
>>>>>>> 2879df7a58ceecdf969da14559dc60490990c64b
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 401),\n",
       " ('of', 213),\n",
       " (',', 180),\n",
       " ('to', 177),\n",
       " ('.', 175),\n",
       " ('and', 139),\n",
       " ('in', 106),\n",
       " ('that', 88),\n",
       " ('a', 70),\n",
       " ('is', 63)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the 10 most common tokens\n",
    "tokens = nltk.word_tokenize(speech)\n",
    "fd = nltk.collocations.FreqDist(tokens)\n",
    "fd.most_common()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "The process of classifying words into their parts of speech and labeling them accordingly is known as part-of-speech tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('indeed', 'RB'),\n",
       " ('a', 'DT'),\n",
       " ('pleasure', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('me', 'PRP'),\n",
       " ('and', 'CC')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged = nltk.pos_tag(tokens[2:8])\n",
    "tagged"
=======
    "Not so interesting as the most common words seem to be words that have no particular meanings."
>>>>>>> 2879df7a58ceecdf969da14559dc60490990c64b
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common step in text analysis is to remove noise. *However*, what you deem \"noise\" is not only very important but also dependent on the project at hand. For the purposes of today, we will discuss two common categories of strings often considered \"noise\". \n",
    "\n",
    "- Punctuation: While important for sentence analysis, punctuation will get in the way of word frequency and n-gram analyses. They will also affect any clustering on topic modeling.\n",
    "\n",
    "- Stopwords: Stopwords are the most frequent words in any given language. Words like \"the\", \"a\", \"that\", etc. are considered not semantically important, and would also skew any frequency or n-gram analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question</b> Write a function below that takes a string as an argument and returns a list of words without punctuation or stopwords.\n",
    "\n",
    "`punctuation` is a list of punctuation strings, and we have created the list `stop_words` for you.\n",
    "\n",
    "Hint: first you'll want to remove punctuation, then tokenize, then remove stop words. Make sure you account for upper and lower case!"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
=======
   "execution_count": 9,
>>>>>>> 2879df7a58ceecdf969da14559dc60490990c64b
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "    \n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "punctuation = set(punctuation)\n",
    "\n",
    "def rem_punc_stop(text):\n",
    "    \n",
    "    punc_free = \"\".join([ch for ch in text if ch not in punctuation])\n",
    "    \n",
    "    words = nltk.word_tokenize(punc_free)\n",
    "    \n",
    "    noise_free = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    return noise_free"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can rerun our frequency analysis without the noise:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
=======
   "execution_count": 10,
>>>>>>> 2879df7a58ceecdf969da14559dc60490990c64b
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('We', 43),\n",
       " ('The', 35),\n",
       " ('international', 29),\n",
       " ('Nations', 24),\n",
       " ('United', 23),\n",
       " ('countries', 22),\n",
       " ('Africa', 19),\n",
       " ('Assembly', 18),\n",
       " ('African', 16),\n",
       " ('also', 15)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('stopwords')\n",
    "tokens_reduced = rem_punc_stop(speech)\n",
    "fd_reduced = nltk.collocations.FreqDist(tokens_reduced)\n",
    "fd_reduced.most_common()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our analysis is much more informational and revealing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming <a id='section 2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In NLP it is often the case that the specific form of a word is not as important as the idea to which it refers. For example, if you are trying to identify the topic of a document, counting 'running', 'runs', 'ran', and 'run' as four separate words is not useful. Reducing words to their stems is a process called stemming.\n",
    "\n",
    "A popular stemming implementation is the Snowball Stemmer, which is based on the Porter Stemmer. Its algorithm looks at word forms and does things like drop final 's's, 'ed's, and 'ing's.\n",
    "\n",
    "Just like the tokenizers, we first have to create a stemmer object with the language we are using. Refer to [this documentation](http://www.nltk.org/howto/stem.html) to create a snowball stemmer."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 22,
=======
   "execution_count": 11,
>>>>>>> 2879df7a58ceecdf969da14559dc60490990c64b
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball = nltk.SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can try stemming some words"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 23,
=======
   "execution_count": 12,
>>>>>>> 2879df7a58ceecdf969da14559dc60490990c64b
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball.stem('running')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 24,
=======
   "execution_count": 13,
>>>>>>> 2879df7a58ceecdf969da14559dc60490990c64b
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball.stem('eats')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 25,
=======
   "execution_count": 14,
>>>>>>> 2879df7a58ceecdf969da14559dc60490990c64b
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'embarass'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball.stem('embarassed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Snowball is a very fast algorithm, but it has a lot of edge cases. In some cases, words with the same stem are reduced to two different stems"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
=======
   "execution_count": 15,
>>>>>>> 2879df7a58ceecdf969da14559dc60490990c64b
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('cylind', 'cylindr')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball.stem('cylinder'), snowball.stem('cylindrical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes two different words are reduced to the same stem."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 27,
=======
   "execution_count": 16,
>>>>>>> 2879df7a58ceecdf969da14559dc60490990c64b
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('vacat', 'vacat')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball.stem('vacation'), snowball.stem('vacate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question</b> How would the above two situations affect our text analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking<a id='section 3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>POS tagging</b> The process of classifying words into their parts of speech and labeling them accordingly is known as part-of-speech tagging.\n",
    "\n",
    "Take a look at different [POS tags](http://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('like', 'IN'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('outset', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('express', 'VB')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged = nltk.pos_tag(tokens[2:8])\n",
    "tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to work with larger segments of text than single words (but still smaller than a sentence). For instance, in the sentence \"The black cat climbed over the tall fence\", we might want to treat \"The black cat\" as one thing (the subject), \"climbed over\" as a distinct act, and \"the tall fence\" as another thing (the object). The first and third sequences are noun phrases, and the second is a verb phrase.\n",
    "\n",
    "We can separate these phrases by \"chunking\" the sentence, i.e. splitting it into larger chunks than individual tokens. This is also an important step toward identifying entities, which are often represented by more than one word. You can probably imagine certain patterns that would define a noun phrase, using part of speech tags. For instance, a determiner (e.g. an article like \"the\") could be concatenated onto the noun that follows it. If there's an adjective between them, we can include that too.\n",
    "\n",
    "To define rules about how to structure words based on their part of speech tags, we use a grammar (in this case, a \"chunk grammar\"). NLTK provides a RegexpParser that takes as input a grammar composed of regular expressions (which define patterns in text, we'll learn it in later labs). The grammar is defined as a string, with one line for each rule we define. Each rule starts with the label we want to assign to the chunk (e.g. NP for \"noun phrase\"), followed by a colon, then an expression in regex-like notation that will be matched to tokens' POS (part-of-speech) tags.\n",
    "\n",
    "We can define a single rule for a noun phrase like this. The rule allows 0 or 1 determiner, then 0 or more adjectives, and finally at least 1 noun. (By using 'NN.*' as the last POS tag, we can match 'NN', 'NNP' for a proper noun, or 'NNS' for a plural noun.) If a matching sequence of tokens is found, it will be labeled 'NP'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = \"NP: {<DT>?<JJ>*<NN.*>+}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a chunk parser object by supplying this grammar, then use it to parse a sentence into chunks. The sentence we want to parse must already be POS-tagged, since our grammar uses those POS tags to identify chunks. Let's try this on the second sentence of the speech we generated above."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 29,
=======
   "execution_count": 22,
>>>>>>> 2879df7a58ceecdf969da14559dc60490990c64b
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unanimity of that decision reflects not only your own distinguished record as Foreign Minister and Permanent Representative of your country to the United Nations but also the prestige of your country, Nigeria, of which all of us in Africa are proud. \n",
      "\n",
      "(S\n",
      "  (NP The/DT unanimity/NN)\n",
      "  of/IN\n",
      "  (NP that/DT decision/NN)\n",
      "  reflects/VBZ\n",
      "  not/RB\n",
      "  only/RB\n",
      "  your/PRP$\n",
      "  (NP own/JJ distinguished/JJ record/NN)\n",
      "  as/IN\n",
      "  (NP Foreign/NNP Minister/NNP)\n",
      "  and/CC\n",
      "  (NP Permanent/NNP Representative/NNP)\n",
      "  of/IN\n",
      "  your/PRP$\n",
      "  (NP country/NN)\n",
      "  to/TO\n",
      "  (NP the/DT United/NNP Nations/NNPS)\n",
      "  but/CC\n",
      "  also/RB\n",
      "  (NP the/DT prestige/NN)\n",
      "  of/IN\n",
      "  your/PRP$\n",
      "  (NP country/NN)\n",
      "  ,/,\n",
      "  (NP Nigeria/NNP)\n",
      "  ,/,\n",
      "  of/IN\n",
      "  which/WDT\n",
      "  all/DT\n",
      "  of/IN\n",
      "  us/PRP\n",
      "  in/IN\n",
      "  (NP Africa/NNP)\n",
      "  are/VBP\n",
      "  proud/JJ\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "# tokenize the second sentence\n",
    "sent1 = sents[1]\n",
    "print(sent1, \"\\n\")\n",
    "sent1_tokens = nltk.word_tokenize(sent1)\n",
    "\n",
    "\n",
    "from nltk import RegexpParser\n",
    "\n",
    "cp = RegexpParser(grammar)\n",
    "\n",
    "sent1_tagged = nltk.pos_tag(sent1_tokens)\n",
    "sent1_chunked = cp.parse(sent1_tagged)\n",
    "\n",
    "print(sent1_chunked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we called print() on this chunked sentence, it printed out a nested list of nodes."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 30,
=======
   "execution_count": 24,
>>>>>>> 2879df7a58ceecdf969da14559dc60490990c64b
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.tree.Tree"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sent1_chunked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree is pretty flat, because we defined a grammar that only grouped words into non-overlapping noun phrases, with no additional hierarchy above them. This is sometimes referred to as \"shallow parsing\". Run the next cell to see a representation of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                   S                                                                                                                                                                                                                                                                    \n",
      "   ________________________________________________________________________________________________________________________________________________________________|______________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________       \n",
      "  |        |         |       |        |       |     |      |       |       |     |       |      |       |      |   |    |       |       |      |     |      |      |       |      |          NP                       NP                           NP                               NP                             NP                     NP                NP                          NP                 NP          NP         NP    \n",
      "  |        |         |       |        |       |     |      |       |       |     |       |      |       |      |   |    |       |       |      |     |      |      |       |      |     _____|_______            _____|_______          ___________|_____________            _______|_______               ________|_________             |         ________|___________           _____|_______           |           |          |      \n",
      "of/IN reflects/VBZ not/RB only/RB your/PRP$ as/IN and/CC of/IN your/PRP$ to/TO but/CC also/RB of/IN your/PRP$ ,/, ,/, of/IN which/WDT all/DT of/IN us/PRP in/IN are/VBP proud/JJ ./. The/DT     unanimity/NN that/DT     decision/NN own/JJ distinguished/JJ record/NN Foreign/NNP     Minister/NNP Permanent/NNP     Representative/ country/NN the/DT United/NNP Nations/NNPS the/DT     prestige/NN country/NN Nigeria/NNP Africa/NNP\n",
      "                                                                                                                                                                                                                                                                                                                            NNP                                                                                                         \n",
      "\n"
     ]
    }
   ],
   "source": [
    "nltk.tree.Tree.fromstring(str(sent1_chunked)).pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more interesting trees, we need to add more phrase types, including those that contain other phrase types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar2 = r\"\"\"\n",
    "    NP: {<DT>?<JJ>*<NN.*>+}      # Chunk sequences of DT, JJ, NN\n",
    "    PP: {<IN><NP>}               # Chunk prepositions followed by NP\n",
    "    VP: {<VB.*><NP|PP|CLAUSE>+} # Chunk verbs and their arguments\n",
    "    CLAUSE: {<NP><VP>}           # Chunk NP, VP into a clause\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question:</b> write code that chunks the second sentence of the speech `sent2` using `grammar2`. Remember, you need to:\n",
    "- create a RegexpParser using `grammar2`\n",
    "- tokenize and POS tag `sent2`\n",
    "- make a Tree by using your new parser to parse your tokenized, POS-tagged sentence\n",
    "\n",
    "Save your Tree to the variable `sent2_chunked`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The outgoing President of the General Assembly, Mr. Dante Caputo of Argentina, shouldered the responsibility of his office with distinction in a momentous and difficult year.\n",
      "(S\n",
      "  The/DT\n",
      "  (VP\n",
      "    outgoing/VBG\n",
      "    (NP President/NNP)\n",
      "    (PP of/IN (NP the/DT General/NNP Assembly/NNP)))\n",
      "  ,/,\n",
      "  (NP Mr./NNP Dante/NNP Caputo/NNP)\n",
      "  (PP of/IN (NP Argentina/NNP))\n",
      "  ,/,\n",
      "  (VP shouldered/VBD (NP the/DT responsibility/NN))\n",
      "  of/IN\n",
      "  his/PRP$\n",
      "  (NP office/NN)\n",
      "  (PP with/IN (NP distinction/NN))\n",
      "  in/IN\n",
      "  a/DT\n",
      "  momentous/JJ\n",
      "  and/CC\n",
      "  (NP difficult/JJ year/NN)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "sent2 = sents[2]\n",
    "print(sent2)\n",
    "\n",
    "# your code here\n",
    "sent2_tokens = nltk.word_tokenize(sent2)\n",
    "\n",
    "\n",
    "from nltk import RegexpParser\n",
    "\n",
    "cp = RegexpParser(grammar2)\n",
    "\n",
    "sent2_tagged = nltk.pos_tag(sent2_tokens)\n",
    "sent2_chunked = cp.parse(sent2_tagged)\n",
    "\n",
    "print(sent2_chunked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                  S                                                                                                                                                                               \n",
      "   _______________________________________________________________________________________________________________|_____________________________________________________________________________________________________________________________________________________________________           \n",
      "  |     |   |    |      |       |    |        |         |     |                               VP                                                  |                       |                                 |                            |              |                               |         \n",
      "  |     |   |    |      |       |    |        |         |     |        _______________________|___________                                        |                       |                                 |                            |              |                               |          \n",
      "  |     |   |    |      |       |    |        |         |     |       |             |                     PP                                      |                       PP                                VP                           |              PP                              |         \n",
      "  |     |   |    |      |       |    |        |         |     |       |             |          ___________|_______                                |                   ____|________               __________|_____                       |         _____|________                       |          \n",
      "  |     |   |    |      |       |    |        |         |     |       |             NP        |                   NP                              NP                 |             NP            |                NP                     NP       |              NP                     NP        \n",
      "  |     |   |    |      |       |    |        |         |     |       |             |         |      _____________|___________            ________|_________         |             |             |           _____|_________             |        |              |              ________|_____     \n",
      "The/DT ,/, ,/, of/IN his/PRP$ in/IN a/DT momentous/JJ and/CC ./. outgoing/VBG President/NNP of/IN the/DT     General/NNP Assembly/NNP Mr./NNP Dante/NNP Caputo/NNP of/IN     Argentina/NNP shouldered/VBD the/DT     responsibility/ office/NN with/IN     distinction/NN difficult/JJ     year/NN\n",
      "                                                                                                                                                                                                                            NN                                                                    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "nltk.tree.Tree.fromstring(str(sent2_chunked)).pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining it all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that takes in a strubg, tokenizes it, removes noise, turns everything to lower-case, and returns a string of stems of all tokens.\n",
    "\n",
    "Hint: any function from above that we can just grab and use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder, this is what our table looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>year</th>\n",
       "      <th>country</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>1989</td>\n",
       "      <td>MDV</td>\n",
       "      <td>﻿It is indeed a pleasure for me and the member...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>1989</td>\n",
       "      <td>FIN</td>\n",
       "      <td>﻿\\nMay I begin by congratulating you. Sir, on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>1989</td>\n",
       "      <td>NER</td>\n",
       "      <td>﻿\\nMr. President, it is a particular pleasure ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>1989</td>\n",
       "      <td>URY</td>\n",
       "      <td>﻿\\nDuring the debate at the fortieth session o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44</td>\n",
       "      <td>1989</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>﻿I should like at the outset to express my del...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session  year country                                               text\n",
       "0       44  1989     MDV  ﻿It is indeed a pleasure for me and the member...\n",
       "1       44  1989     FIN  ﻿\\nMay I begin by congratulating you. Sir, on ...\n",
       "2       44  1989     NER  ﻿\\nMr. President, it is a particular pleasure ...\n",
       "3       44  1989     URY  ﻿\\nDuring the debate at the fortieth session o...\n",
       "4       44  1989     ZWE  ﻿I should like at the outset to express my del..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def does_it_all(text):\n",
    "    tokens = \"\"\n",
    "    \n",
    "    not_stemmed = rem_punc_stop(text)\n",
    "    stemmed = [snowball.stem(word.lower()) for word in not_stemmed]\n",
    "    for word in not_stemmed:\n",
    "        tokens += snowball.stem(word) + \" \"\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply our function to speeches from 2001.\n",
    "\n",
    "First create a table that includes all 2001 speeches. Refer to [this doc](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.loc.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>year</th>\n",
       "      <th>country</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7318</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>COM</td>\n",
       "      <td>﻿On\\nbehalf of the Comorian delegation, which ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7319</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>RWA</td>\n",
       "      <td>﻿It is a\\ngreat honour for me, on behalf of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7320</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>MMR</td>\n",
       "      <td>﻿On behalf of the\\ndelegation of the Union of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7321</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>PHL</td>\n",
       "      <td>﻿Let me begin by\\ncongratulating Your Excellen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7322</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>MRT</td>\n",
       "      <td>﻿I\\nam delighted to be able to congratulate yo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      session  year country                                               text\n",
       "7318       56  2001     COM  ﻿On\\nbehalf of the Comorian delegation, which ...\n",
       "7319       56  2001     RWA  ﻿It is a\\ngreat honour for me, on behalf of th...\n",
       "7320       56  2001     MMR  ﻿On behalf of the\\ndelegation of the Union of ...\n",
       "7321       56  2001     PHL  ﻿Let me begin by\\ncongratulating Your Excellen...\n",
       "7322       56  2001     MRT  ﻿I\\nam delighted to be able to congratulate yo..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech_2001 = data.loc[data['year'] == 2001]\n",
    "speech_2001.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create a new column in speech_2001 which contains the tokenized string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>year</th>\n",
       "      <th>country</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7318</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>COM</td>\n",
       "      <td>﻿On\\nbehalf of the Comorian delegation, which ...</td>\n",
       "      <td>﻿on behalf comorian deleg i honour lead behalf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7319</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>RWA</td>\n",
       "      <td>﻿It is a\\ngreat honour for me, on behalf of th...</td>\n",
       "      <td>﻿it great honour behalf rwandan deleg join pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7320</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>MMR</td>\n",
       "      <td>﻿On behalf of the\\ndelegation of the Union of ...</td>\n",
       "      <td>﻿on behalf deleg union myanmar i wish extend w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7321</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>PHL</td>\n",
       "      <td>﻿Let me begin by\\ncongratulating Your Excellen...</td>\n",
       "      <td>﻿let begin congratul your excel mr han seungso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7322</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>MRT</td>\n",
       "      <td>﻿I\\nam delighted to be able to congratulate yo...</td>\n",
       "      <td>﻿i delight abl congratul sir behalf deleg isla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7323</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>UZB</td>\n",
       "      <td>﻿Allow me to convey our sincere congratulation...</td>\n",
       "      <td>﻿allow convey sincer congratul mr kofi annan o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7324</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>AGO</td>\n",
       "      <td>﻿Allow me to\\nstart by congratulating you, Mr....</td>\n",
       "      <td>﻿allow start congratul mr presid behalf govern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7325</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>SUR</td>\n",
       "      <td>﻿My delegation cannot\\nfind the words to conve...</td>\n",
       "      <td>﻿mi deleg find word convey sad plane crash occ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7326</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>EGY</td>\n",
       "      <td>﻿Allow me to read the statement that was to be...</td>\n",
       "      <td>﻿allow read statement deliv minist foreign aff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7327</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>SLB</td>\n",
       "      <td>﻿At the outset,\\nlet me express my sincere fel...</td>\n",
       "      <td>﻿at outset let express sincer felicit govern p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7328</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>BGR</td>\n",
       "      <td>﻿A year after the unique Millennium Assembly,\\...</td>\n",
       "      <td>﻿a year uniqu millennium assembl say unit nati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7329</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>GRD</td>\n",
       "      <td>﻿At the outset, my\\ndelegation extends profoun...</td>\n",
       "      <td>﻿at outset deleg extend profound sympathi fami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7330</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>NER</td>\n",
       "      <td>﻿The\\nfact that we are meeting under the presi...</td>\n",
       "      <td>﻿the fact meet presid one emin person republ k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7331</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>HTI</td>\n",
       "      <td>﻿On behalf\\nof the President of the Republic o...</td>\n",
       "      <td>﻿on behalf presid republ haiti haitian deleg i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7332</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>CRI</td>\n",
       "      <td>﻿Allow me at the outset to congratulate you,\\n...</td>\n",
       "      <td>﻿allow outset congratul sir welldeserv elect p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7333</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>MNG</td>\n",
       "      <td>﻿At the outset, I wish\\nto pay tribute to the ...</td>\n",
       "      <td>﻿at outset i wish pay tribut secretarygener mr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7334</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>GRC</td>\n",
       "      <td>﻿Allow me to\\ncongratulate the President, Mr. ...</td>\n",
       "      <td>﻿allow congratul presid mr han seungsoo elect ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7335</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>ISR</td>\n",
       "      <td>﻿First of all, I would really like\\nto congrat...</td>\n",
       "      <td>﻿first i would realli like congratul sir elect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7336</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>QAT</td>\n",
       "      <td>﻿It is my pleasure to address the\\nGeneral Ass...</td>\n",
       "      <td>﻿it pleasur address general assembl today capa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7337</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>COD</td>\n",
       "      <td>﻿Allow\\nme, at the outset, to add my voice to ...</td>\n",
       "      <td>﻿allow outset add voic distinguish speaker off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7338</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>ERI</td>\n",
       "      <td>﻿Please\\nallow me to extend to you, Sir, on be...</td>\n",
       "      <td>﻿pleas allow extend sir behalf deleg eritrea w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7339</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>UGA</td>\n",
       "      <td>﻿There is a lot of talk\\nfloating around regar...</td>\n",
       "      <td>﻿there lot talk float around regard catchword ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7340</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>MDV</td>\n",
       "      <td>﻿It gives me great\\npleasure, on behalf of my ...</td>\n",
       "      <td>﻿it give great pleasur behalf countri congratu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7341</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>THA</td>\n",
       "      <td>﻿It is an honour for\\nme to deliver this state...</td>\n",
       "      <td>﻿it honour deliv statement behalf mr surakiart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7342</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>DJI</td>\n",
       "      <td>﻿In view\\nof the catastrophic events that took...</td>\n",
       "      <td>﻿in view catastroph event took place 11 septem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7343</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>MHL</td>\n",
       "      <td>﻿On behalf of the\\nGovernment and the people o...</td>\n",
       "      <td>﻿on behalf govern peopl republ marshal island ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7344</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>PAK</td>\n",
       "      <td>﻿I would like to\\nextend to you, Mr. President...</td>\n",
       "      <td>﻿i would like extend mr presid felicit elect i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7345</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>STP</td>\n",
       "      <td>﻿Mr. President, allow me to\\ncongratulate you ...</td>\n",
       "      <td>﻿mr presid allow congratul behalf state sao to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7346</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>CAF</td>\n",
       "      <td>﻿The delegation of the Central African\\nRepubl...</td>\n",
       "      <td>﻿the deleg central african republ would like f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7347</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>NRU</td>\n",
       "      <td>﻿I bid the Assembly welcome\\nfrom the people o...</td>\n",
       "      <td>﻿i bid assembl welcom peopl nauru pleasant lit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7477</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>GBR</td>\n",
       "      <td>﻿Please allow me\\nwarmly to congratulate you, ...</td>\n",
       "      <td>﻿pleas allow warm congratul sir assumpt presid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7478</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>ESP</td>\n",
       "      <td>﻿First of\\nall, I would like to congratulate M...</td>\n",
       "      <td>﻿first i would like congratul mr han seungsoo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7479</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>COG</td>\n",
       "      <td>﻿The crash\\nof American Airlines flight 587 tw...</td>\n",
       "      <td>﻿the crash american airlin flight 587 two day ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7480</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>LKA</td>\n",
       "      <td>﻿Every speaker\\nfrom this podium during the sp...</td>\n",
       "      <td>﻿everi speaker podium special debat terror deb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7481</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>KGZ</td>\n",
       "      <td>﻿Osmonakun IbraimovI\\nwould like at the outset...</td>\n",
       "      <td>﻿osmonakun ibraimovi would like outset join co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7482</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>TJK</td>\n",
       "      <td>﻿This\\nsession of the General Assembly is faci...</td>\n",
       "      <td>﻿this session general assembl face import task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7483</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>IND</td>\n",
       "      <td>﻿I congratulate the President on his election ...</td>\n",
       "      <td>﻿i congratul presid elect presid general assem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7484</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>YEM</td>\n",
       "      <td>﻿I am\\npleased, first of all, to convey throug...</td>\n",
       "      <td>﻿i pleas first convey sir sincer congratul pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7485</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>CZE</td>\n",
       "      <td>﻿Let me\\ncongratulate Mr. Han Seung-soo on his...</td>\n",
       "      <td>﻿let congratul mr han seungsoo elect presid fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7486</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>NAM</td>\n",
       "      <td>﻿The fifty-sixth session\\nof the General Assem...</td>\n",
       "      <td>﻿the fiftysixth session general assembl ordina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7487</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>DMA</td>\n",
       "      <td>﻿I am pleased and\\nhonoured to address the Ass...</td>\n",
       "      <td>﻿i pleas honour address assembl behalf govern ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7488</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>SWE</td>\n",
       "      <td>﻿Let me start by\\ncongratulating the United Na...</td>\n",
       "      <td>﻿let start congratul unit nation secretari gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7489</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>NLD</td>\n",
       "      <td>﻿How can anyone\\nstand on the smoking ashes of...</td>\n",
       "      <td>﻿how anyon stand smoke ash “ ground zero ” ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7490</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>GAB</td>\n",
       "      <td>﻿\\nI would like to begin by congratulating the...</td>\n",
       "      <td>﻿ i would like begin congratul presid outstand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7491</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>LBY</td>\n",
       "      <td>﻿At the\\noutset, I would like to congratulate ...</td>\n",
       "      <td>﻿at outset i would like congratul presid unani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7492</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>LIE</td>\n",
       "      <td>﻿Let me first join\\nprevious speakers in expre...</td>\n",
       "      <td>﻿let first join previous speaker express heart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7493</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>BLR</td>\n",
       "      <td>﻿The\\ndelegation of Belarus would like to expr...</td>\n",
       "      <td>﻿the deleg belarus would like express deepest ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7494</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>ITA</td>\n",
       "      <td>﻿I wish to congratulate the\\nPresident on his ...</td>\n",
       "      <td>﻿i wish congratul presid elect head first sess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7495</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>ARG</td>\n",
       "      <td>﻿Allow\\nme at the outset to congratulate you, ...</td>\n",
       "      <td>﻿allow outset congratul sir elect presid gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7496</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>LAO</td>\n",
       "      <td>﻿On behalf of the delegation of the Lao\\nPeopl...</td>\n",
       "      <td>﻿on behalf deleg lao peopl ’ democrat republ a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7497</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>MOZ</td>\n",
       "      <td>﻿I wish to congratulate\\nHis Excellency Mr. Ha...</td>\n",
       "      <td>﻿i wish congratul his excel mr han seungsoo up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7498</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>TGO</td>\n",
       "      <td>﻿The sudden\\nspeeding up of events that has ta...</td>\n",
       "      <td>﻿the sudden speed event taken place sinc fifty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>LBN</td>\n",
       "      <td>﻿Mr. President, allow me first to congratulate...</td>\n",
       "      <td>﻿mr presid allow first congratul elect presid ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7500</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>AZE</td>\n",
       "      <td>﻿This session of the\\nGeneral Assembly is bein...</td>\n",
       "      <td>﻿this session general assembl held difficult t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7501</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>MKD</td>\n",
       "      <td>﻿At the outset, allow me to convey our\\ndeepes...</td>\n",
       "      <td>﻿at outset allow convey deepest condol america...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7502</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>KAZ</td>\n",
       "      <td>﻿This session\\nthat is taking place under extr...</td>\n",
       "      <td>﻿this session take place extraordinari circums...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7503</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>LBR</td>\n",
       "      <td>﻿I am honoured to\\nparticipate in this histori...</td>\n",
       "      <td>﻿i honour particip histor session behalf his e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7504</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>BDI</td>\n",
       "      <td>﻿It\\nis for me a signal honour to take the flo...</td>\n",
       "      <td>﻿it signal honour take floor today assembl fif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7505</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>HUN</td>\n",
       "      <td>﻿First, may I congratulate Mr. Han Seung-soo o...</td>\n",
       "      <td>﻿first may i congratul mr han seungsoo elect p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7506</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>KWT</td>\n",
       "      <td>﻿On behalf of the State of Kuwait, it\\ngives m...</td>\n",
       "      <td>﻿on behalf state kuwait give pleasur congratul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      session  year country  \\\n",
       "7318       56  2001     COM   \n",
       "7319       56  2001     RWA   \n",
       "7320       56  2001     MMR   \n",
       "7321       56  2001     PHL   \n",
       "7322       56  2001     MRT   \n",
       "7323       56  2001     UZB   \n",
       "7324       56  2001     AGO   \n",
       "7325       56  2001     SUR   \n",
       "7326       56  2001     EGY   \n",
       "7327       56  2001     SLB   \n",
       "7328       56  2001     BGR   \n",
       "7329       56  2001     GRD   \n",
       "7330       56  2001     NER   \n",
       "7331       56  2001     HTI   \n",
       "7332       56  2001     CRI   \n",
       "7333       56  2001     MNG   \n",
       "7334       56  2001     GRC   \n",
       "7335       56  2001     ISR   \n",
       "7336       56  2001     QAT   \n",
       "7337       56  2001     COD   \n",
       "7338       56  2001     ERI   \n",
       "7339       56  2001     UGA   \n",
       "7340       56  2001     MDV   \n",
       "7341       56  2001     THA   \n",
       "7342       56  2001     DJI   \n",
       "7343       56  2001     MHL   \n",
       "7344       56  2001     PAK   \n",
       "7345       56  2001     STP   \n",
       "7346       56  2001     CAF   \n",
       "7347       56  2001     NRU   \n",
       "...       ...   ...     ...   \n",
       "7477       56  2001     GBR   \n",
       "7478       56  2001     ESP   \n",
       "7479       56  2001     COG   \n",
       "7480       56  2001     LKA   \n",
       "7481       56  2001     KGZ   \n",
       "7482       56  2001     TJK   \n",
       "7483       56  2001     IND   \n",
       "7484       56  2001     YEM   \n",
       "7485       56  2001     CZE   \n",
       "7486       56  2001     NAM   \n",
       "7487       56  2001     DMA   \n",
       "7488       56  2001     SWE   \n",
       "7489       56  2001     NLD   \n",
       "7490       56  2001     GAB   \n",
       "7491       56  2001     LBY   \n",
       "7492       56  2001     LIE   \n",
       "7493       56  2001     BLR   \n",
       "7494       56  2001     ITA   \n",
       "7495       56  2001     ARG   \n",
       "7496       56  2001     LAO   \n",
       "7497       56  2001     MOZ   \n",
       "7498       56  2001     TGO   \n",
       "7499       56  2001     LBN   \n",
       "7500       56  2001     AZE   \n",
       "7501       56  2001     MKD   \n",
       "7502       56  2001     KAZ   \n",
       "7503       56  2001     LBR   \n",
       "7504       56  2001     BDI   \n",
       "7505       56  2001     HUN   \n",
       "7506       56  2001     KWT   \n",
       "\n",
       "                                                   text  \\\n",
       "7318  ﻿On\\nbehalf of the Comorian delegation, which ...   \n",
       "7319  ﻿It is a\\ngreat honour for me, on behalf of th...   \n",
       "7320  ﻿On behalf of the\\ndelegation of the Union of ...   \n",
       "7321  ﻿Let me begin by\\ncongratulating Your Excellen...   \n",
       "7322  ﻿I\\nam delighted to be able to congratulate yo...   \n",
       "7323  ﻿Allow me to convey our sincere congratulation...   \n",
       "7324  ﻿Allow me to\\nstart by congratulating you, Mr....   \n",
       "7325  ﻿My delegation cannot\\nfind the words to conve...   \n",
       "7326  ﻿Allow me to read the statement that was to be...   \n",
       "7327  ﻿At the outset,\\nlet me express my sincere fel...   \n",
       "7328  ﻿A year after the unique Millennium Assembly,\\...   \n",
       "7329  ﻿At the outset, my\\ndelegation extends profoun...   \n",
       "7330  ﻿The\\nfact that we are meeting under the presi...   \n",
       "7331  ﻿On behalf\\nof the President of the Republic o...   \n",
       "7332  ﻿Allow me at the outset to congratulate you,\\n...   \n",
       "7333  ﻿At the outset, I wish\\nto pay tribute to the ...   \n",
       "7334  ﻿Allow me to\\ncongratulate the President, Mr. ...   \n",
       "7335  ﻿First of all, I would really like\\nto congrat...   \n",
       "7336  ﻿It is my pleasure to address the\\nGeneral Ass...   \n",
       "7337  ﻿Allow\\nme, at the outset, to add my voice to ...   \n",
       "7338  ﻿Please\\nallow me to extend to you, Sir, on be...   \n",
       "7339  ﻿There is a lot of talk\\nfloating around regar...   \n",
       "7340  ﻿It gives me great\\npleasure, on behalf of my ...   \n",
       "7341  ﻿It is an honour for\\nme to deliver this state...   \n",
       "7342  ﻿In view\\nof the catastrophic events that took...   \n",
       "7343  ﻿On behalf of the\\nGovernment and the people o...   \n",
       "7344  ﻿I would like to\\nextend to you, Mr. President...   \n",
       "7345  ﻿Mr. President, allow me to\\ncongratulate you ...   \n",
       "7346  ﻿The delegation of the Central African\\nRepubl...   \n",
       "7347  ﻿I bid the Assembly welcome\\nfrom the people o...   \n",
       "...                                                 ...   \n",
       "7477  ﻿Please allow me\\nwarmly to congratulate you, ...   \n",
       "7478  ﻿First of\\nall, I would like to congratulate M...   \n",
       "7479  ﻿The crash\\nof American Airlines flight 587 tw...   \n",
       "7480  ﻿Every speaker\\nfrom this podium during the sp...   \n",
       "7481  ﻿Osmonakun IbraimovI\\nwould like at the outset...   \n",
       "7482  ﻿This\\nsession of the General Assembly is faci...   \n",
       "7483  ﻿I congratulate the President on his election ...   \n",
       "7484  ﻿I am\\npleased, first of all, to convey throug...   \n",
       "7485  ﻿Let me\\ncongratulate Mr. Han Seung-soo on his...   \n",
       "7486  ﻿The fifty-sixth session\\nof the General Assem...   \n",
       "7487  ﻿I am pleased and\\nhonoured to address the Ass...   \n",
       "7488  ﻿Let me start by\\ncongratulating the United Na...   \n",
       "7489  ﻿How can anyone\\nstand on the smoking ashes of...   \n",
       "7490  ﻿\\nI would like to begin by congratulating the...   \n",
       "7491  ﻿At the\\noutset, I would like to congratulate ...   \n",
       "7492  ﻿Let me first join\\nprevious speakers in expre...   \n",
       "7493  ﻿The\\ndelegation of Belarus would like to expr...   \n",
       "7494  ﻿I wish to congratulate the\\nPresident on his ...   \n",
       "7495  ﻿Allow\\nme at the outset to congratulate you, ...   \n",
       "7496  ﻿On behalf of the delegation of the Lao\\nPeopl...   \n",
       "7497  ﻿I wish to congratulate\\nHis Excellency Mr. Ha...   \n",
       "7498  ﻿The sudden\\nspeeding up of events that has ta...   \n",
       "7499  ﻿Mr. President, allow me first to congratulate...   \n",
       "7500  ﻿This session of the\\nGeneral Assembly is bein...   \n",
       "7501  ﻿At the outset, allow me to convey our\\ndeepes...   \n",
       "7502  ﻿This session\\nthat is taking place under extr...   \n",
       "7503  ﻿I am honoured to\\nparticipate in this histori...   \n",
       "7504  ﻿It\\nis for me a signal honour to take the flo...   \n",
       "7505  ﻿First, may I congratulate Mr. Han Seung-soo o...   \n",
       "7506  ﻿On behalf of the State of Kuwait, it\\ngives m...   \n",
       "\n",
       "                                                 tokens  \n",
       "7318  ﻿on behalf comorian deleg i honour lead behalf...  \n",
       "7319  ﻿it great honour behalf rwandan deleg join pre...  \n",
       "7320  ﻿on behalf deleg union myanmar i wish extend w...  \n",
       "7321  ﻿let begin congratul your excel mr han seungso...  \n",
       "7322  ﻿i delight abl congratul sir behalf deleg isla...  \n",
       "7323  ﻿allow convey sincer congratul mr kofi annan o...  \n",
       "7324  ﻿allow start congratul mr presid behalf govern...  \n",
       "7325  ﻿mi deleg find word convey sad plane crash occ...  \n",
       "7326  ﻿allow read statement deliv minist foreign aff...  \n",
       "7327  ﻿at outset let express sincer felicit govern p...  \n",
       "7328  ﻿a year uniqu millennium assembl say unit nati...  \n",
       "7329  ﻿at outset deleg extend profound sympathi fami...  \n",
       "7330  ﻿the fact meet presid one emin person republ k...  \n",
       "7331  ﻿on behalf presid republ haiti haitian deleg i...  \n",
       "7332  ﻿allow outset congratul sir welldeserv elect p...  \n",
       "7333  ﻿at outset i wish pay tribut secretarygener mr...  \n",
       "7334  ﻿allow congratul presid mr han seungsoo elect ...  \n",
       "7335  ﻿first i would realli like congratul sir elect...  \n",
       "7336  ﻿it pleasur address general assembl today capa...  \n",
       "7337  ﻿allow outset add voic distinguish speaker off...  \n",
       "7338  ﻿pleas allow extend sir behalf deleg eritrea w...  \n",
       "7339  ﻿there lot talk float around regard catchword ...  \n",
       "7340  ﻿it give great pleasur behalf countri congratu...  \n",
       "7341  ﻿it honour deliv statement behalf mr surakiart...  \n",
       "7342  ﻿in view catastroph event took place 11 septem...  \n",
       "7343  ﻿on behalf govern peopl republ marshal island ...  \n",
       "7344  ﻿i would like extend mr presid felicit elect i...  \n",
       "7345  ﻿mr presid allow congratul behalf state sao to...  \n",
       "7346  ﻿the deleg central african republ would like f...  \n",
       "7347  ﻿i bid assembl welcom peopl nauru pleasant lit...  \n",
       "...                                                 ...  \n",
       "7477  ﻿pleas allow warm congratul sir assumpt presid...  \n",
       "7478  ﻿first i would like congratul mr han seungsoo ...  \n",
       "7479  ﻿the crash american airlin flight 587 two day ...  \n",
       "7480  ﻿everi speaker podium special debat terror deb...  \n",
       "7481  ﻿osmonakun ibraimovi would like outset join co...  \n",
       "7482  ﻿this session general assembl face import task...  \n",
       "7483  ﻿i congratul presid elect presid general assem...  \n",
       "7484  ﻿i pleas first convey sir sincer congratul pre...  \n",
       "7485  ﻿let congratul mr han seungsoo elect presid fi...  \n",
       "7486  ﻿the fiftysixth session general assembl ordina...  \n",
       "7487  ﻿i pleas honour address assembl behalf govern ...  \n",
       "7488  ﻿let start congratul unit nation secretari gen...  \n",
       "7489  ﻿how anyon stand smoke ash “ ground zero ” ove...  \n",
       "7490  ﻿ i would like begin congratul presid outstand...  \n",
       "7491  ﻿at outset i would like congratul presid unani...  \n",
       "7492  ﻿let first join previous speaker express heart...  \n",
       "7493  ﻿the deleg belarus would like express deepest ...  \n",
       "7494  ﻿i wish congratul presid elect head first sess...  \n",
       "7495  ﻿allow outset congratul sir elect presid gener...  \n",
       "7496  ﻿on behalf deleg lao peopl ’ democrat republ a...  \n",
       "7497  ﻿i wish congratul his excel mr han seungsoo up...  \n",
       "7498  ﻿the sudden speed event taken place sinc fifty...  \n",
       "7499  ﻿mr presid allow first congratul elect presid ...  \n",
       "7500  ﻿this session general assembl held difficult t...  \n",
       "7501  ﻿at outset allow convey deepest condol america...  \n",
       "7502  ﻿this session take place extraordinari circums...  \n",
       "7503  ﻿i honour particip histor session behalf his e...  \n",
       "7504  ﻿it signal honour take floor today assembl fif...  \n",
       "7505  ﻿first may i congratul mr han seungsoo elect p...  \n",
       "7506  ﻿on behalf state kuwait give pleasur congratul...  \n",
       "\n",
       "[189 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech_2001_with_tokens = speech_2001.copy()\n",
    "speech_2001_with_tokens['tokens'] = speech_2001['text'].apply(does_it_all)\n",
    "speech_2001_with_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You've learned tokenizing, stemming, and chunking texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Notebook developed by: Tian Qin\n",
    "\n",
    "Data Science Modules: http://data.berkeley.edu/education/modules\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
