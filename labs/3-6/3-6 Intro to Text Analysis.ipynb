{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEGALST-190 Lab 3/6\n",
    "\n",
    "---\n",
    "\n",
    "In this lab, students will learn about dominant language models in natural language processing and the basics of how to implement it in Python. We'll be using the data you extracted from the last lab (un-debates-2001-clean.csv).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "from datascience import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context(\"talk\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "Encoding text as a real-valued feature is especially challenging and many of the standard transformations are lossy. Moreover, all of the earlier transformations (e.g., one-hot encoding and Boolean representations) preserve the information in the feature. In contrast, most of the techniques for encoding text destroy information about the word order and in many cases key parts of the grammar.\n",
    "\n",
    "Here we will discuss one widely used representations of text\n",
    "- <b>Bag-of-Words Encoding</b>: encodes text by the frequency of each word\n",
    "\n",
    "This model was very popular in early text analysis, and continues to be used today. In fact, the models that have replaced it are still very difficult to actually interpret, giving the BoW approach a slight advantage if we want to understand why the model makes certain decisions. Once we have our BoW model we can analyze it in a high-dimensional vector space, which gives us more insights into the similarities and clustering of different texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>session</th> <th>year</th> <th>country</th> <th>text</th> <th>tokens</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>56     </td> <td>2001</td> <td>COM    </td> <td>﻿On\r\n",
       "behalf of the Comorian delegation, which I have the ...</td> <td>﻿on behalf comorian deleg i honour lead behalf i offer s ...</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>56     </td> <td>2001</td> <td>RWA    </td> <td>﻿It is a\r\n",
       "great honour for me, on behalf of the Rwandan\r",
       " ...</td> <td>﻿it great honour behalf rwandan deleg join previous spea ...</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>56     </td> <td>2001</td> <td>MMR    </td> <td>﻿On behalf of the\r\n",
       "delegation of the Union of Myanmar, I ...</td> <td>﻿on behalf deleg union myanmar i wish extend warmest con ...</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>56     </td> <td>2001</td> <td>PHL    </td> <td>﻿Let me begin by\r\n",
       "congratulating Your Excellency, Mr. Ha ...</td> <td>﻿let begin congratul your excel mr han seungsoo elect pr ...</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>56     </td> <td>2001</td> <td>MRT    </td> <td>﻿I\r\n",
       "am delighted to be able to congratulate you, Sir, on ...</td> <td>﻿i delight abl congratul sir behalf deleg islam republ m ...</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (184 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## retrieve our data\n",
    "data = Table.read_table('data/un-debates-2001-clean.csv', index_col=0)\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-Words Encoding\n",
    "\n",
    "The bag-of-words encoding is widely used and a standard representation for text in many of the popular text clustering algorithms.\n",
    "\n",
    "__Key Things to Note:__\n",
    "\n",
    "1. __Stop words are removed.__ Stop-words are words like is and about that in isolation contain very little information about the meaning of the sentence. Here is a good list of stop-words in many languages.\n",
    "2. __Word order information is lost.__ Nonetheless the vector still suggests that the sentence is about fun, machines, and learning. Thought there are many possible meanings learning machines have fun learning or learning about machines is fun learning ...\n",
    "3. __Capitalization and punctuation__ are typically removed.\n",
    "4. __Sparse Encoding:__ is necessary to represent the bag-of-words efficiently. There are millions of possible words (including terminology, names, and misspellings) and so instantiating a 0 for every word that is not in each record would be incredibly inefficient.\n",
    "\n",
    "Why is it called a __bag-of-words__?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__SOLUTION:__ A bag is another term for a __multiset__: _an unordered collection which may contain multiple instances of each element._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the Bag-of-words Model\n",
    "\n",
    "We can use sklearn to construct a bag-of-words representation of text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Construct the tokenizer with English stop words\n",
    "bow = CountVectorizer(stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
